{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkarab/diplomaThesis/blob/feat%2F76-feat-siamese-network-callbacks/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEWqBbpav0ht"
      },
      "source": [
        " # 1 - REQUIREMENTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKvCEX4Ejp7g",
        "outputId": "4c7c6df0-a85d-4ca4-fb98-a3c4dd150b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# @title Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "l8K1xVn0k9oi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4918fc3-c07a-4c3e-b5f0-b8c6c39d658f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.10.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.66.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.12.1)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# @title Install tensorflow older version\n",
        "!pip install tensorflow==2.10.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzNFw0LhjmMl",
        "outputId": "190489ef-2493-4519-d2e4-85baa124e3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.10.0\n"
          ]
        }
      ],
      "source": [
        "# @title Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import json\n",
        "from keras import utils, initializers, regularizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Lambda, TimeDistributed\n",
        "from keras import callbacks as cb\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import random\n",
        "import scipy\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.fft import fft, ifft\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_7-xLQ5OUi1b",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Paths\n",
        "ROOT = '/content/drive/MyDrive'\n",
        "\n",
        "#My google Drive\n",
        "drivePath = '/content/drive/MyDrive'\n",
        "\n",
        "#Colab Notebooks\n",
        "colabNotebooksPath = drivePath+'/Colab Notebooks'\n",
        "modulesPath = colabNotebooksPath + '/Modules'\n",
        "nb_path = '/content/notebooks'  #Εκεί βρίσκονται τα εκτελέσιμα και οι βιβλιοθήκες\n",
        "\n",
        "\n",
        "#Python files\n",
        "sourcefilePath = drivePath+'/Source Files'\n",
        "\n",
        "#Data files\n",
        "dataPath = drivePath + '/Data'\n",
        "ninaproPath = dataPath + '/Ninapro'\n",
        "separatedDataPath = dataPath + '/Separated'\n",
        "db2SeparatedPath = os.path.join(separatedDataPath,'db2.npz')\n",
        "preprocessedDataPath = dataPath + '/Preprocessed'\n",
        "db2ProcessedPath = os.path.join(preprocessedDataPath,'DB2')\n",
        "\n",
        "#Data\n",
        "DATA_PATH = ROOT + r'/Data'\n",
        "NINAPRO_PATH = ROOT + r'/Data/Ninapro'\n",
        "SEPARATED_DATA_PATH = os.path.join(DATA_PATH ,'Separated')\n",
        "\n",
        "PROCESSED_DATA_PATH_DB2 = ROOT + r'/Data/Preprocessed/DB2'\n",
        "PROCESSED_DATA_PATH_DB1 = ROOT + r'/Data/Preprocessed/DB1'\n",
        "PROCESSED_DATA_PATH_DB5 = ROOT + r'/Data/Preprocessed/DB5'\n",
        "\n",
        "RMS_DATA_PATH_DB1 = os.path.join(PROCESSED_DATA_PATH_DB1,'rms')\n",
        "RMS_DATA_PATH_DB2 = os.path.join(PROCESSED_DATA_PATH_DB2,'rms')\n",
        "RMS_DATA_PATH_DB5 = os.path.join(PROCESSED_DATA_PATH_DB5,'rms')\n",
        "\n",
        "#Tasks\n",
        "TASKS_FILE_PATH_DB1 = ROOT + r'/Data/Tasks/DB1'\n",
        "TASKS_FILE_PATH_DB2 = ROOT + r'/Data/Tasks/DB2'\n",
        "TASKS_FILE_PATH_DB5 = ROOT + r'/Data/Tasks/DB5'\n",
        "\n",
        "#Results\n",
        "RESULTS_PATH_EX1  = ROOT + r'/Data/Results/Experiment 1'\n",
        "RESULTS_PATH_EX2A = ROOT + r'/Data/Results/Experiment 2a'\n",
        "RESULTS_PATH_EX2B = ROOT + r'/Data/Results/Experiment 2b'\n",
        "RESULTS_PATH_EX3  = ROOT + r'/Data/Results/Experiment 3'\n",
        "RESULTS_DIRECTORIES_DICT = {\n",
        "    '1' : RESULTS_PATH_EX1,\n",
        "    '2a': RESULTS_PATH_EX2A,\n",
        "    '2b': RESULTS_PATH_EX2B,\n",
        "    '3' : RESULTS_PATH_EX3\n",
        "}\n",
        "\n",
        "#Config\n",
        "DATA_CONFIG_PATH_PREPROC = ROOT + r'/Data/Config/preproc'\n",
        "DATA_CONFIG_PATH_AUG = ROOT + r'/Data/Config/aug'\n",
        "\n",
        "#Images\n",
        "imagesPath = drivePath + '/Images'\n",
        "imagesPreprocessingPath = imagesPath + '/Preprocessing'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbXU2DSrwU_Y"
      },
      "source": [
        "# 2 - MODELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "tIGIkdNHlKMg"
      },
      "outputs": [],
      "source": [
        "# @title Custom models\n",
        "\n",
        "def AtzoriNetDB2_embedding_only(input_shape = (15,12,1), add_dropout = False, dropout_pct = 0.15, krnl_init_name = \"glorot_normal\", add_regularizer:bool = False, l2 = 0.0002):\n",
        "    # Kernel Initializer\n",
        "    if krnl_init_name == \"glorot_normal\":\n",
        "        kernel_init = initializers.glorot_normal(seed=0)\n",
        "    else:\n",
        "        kernel_init = initializers.glorot_uniform(seed=0)\n",
        "\n",
        "    if add_regularizer:\n",
        "        kernel_reg = regularizers.l2(l2)\n",
        "    else:\n",
        "        kernel_reg = None\n",
        "\n",
        "    # Input\n",
        "    X_inp = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Layer 1: Padding (0,5) -> Conv2D [32 x (1,12)] -> ReLU\n",
        "    # Input:  (15,12,1)\n",
        "    # Output: (15,11,32)\n",
        "    # X = layers.BatchNormalization(X_inp)\n",
        "    X = layers.BatchNormalization()(X_inp)\n",
        "    X = layers.ZeroPadding2D(padding=(0, 5))(X)\n",
        "    X = layers.Conv2D(filters=32, kernel_size=(1, 12), padding='valid', activation='relu', kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(X)\n",
        "    if add_dropout == True:\n",
        "        X = layers.Dropout(dropout_pct)(X)\n",
        "\n",
        "    # Layer 2: Padding (1,1) -> Conv2D [32 x (3,3)] -> ReLU -> AvgPooling(3,3)\n",
        "    # Input:  (15,11,32)\n",
        "    # Output: (5,3,32)\n",
        "    X = layers.BatchNormalization()(X)\n",
        "    X = layers.ZeroPadding2D(padding=(1, 1))(X)\n",
        "    X = layers.Conv2D(filters=32, kernel_size=(3, 3), padding='valid', activation='relu', kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(X)\n",
        "    if add_dropout == True:\n",
        "        X = layers.Dropout(dropout_pct)(X)\n",
        "    X = layers.AveragePooling2D(pool_size=(3, 3))(X)\n",
        "\n",
        "    # Layer 3: Padding (2,2) -> Conv2D [64 x (5,5)] -> ReLU -> AvgPooling(3,3)\n",
        "    # Input:  (5,3,32)\n",
        "    # Output: (1,1,64)\n",
        "    X = layers.BatchNormalization()(X)\n",
        "    X = layers.ZeroPadding2D(padding=(2, 2))(X)\n",
        "    X = layers.Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu', kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(X)\n",
        "    if add_dropout == True:\n",
        "        X = layers.Dropout(dropout_pct)(X)\n",
        "    X = layers.AveragePooling2D(pool_size=(3, 3))(X)\n",
        "\n",
        "    # Layer 4: Padding (4,0) -> Conv2D [64 x (9,1)] -> ReLU\n",
        "    # The Output is a vector of length 64 corresponding to the input image\n",
        "    # Input:  (1,1,64)\n",
        "    # Output: (1,1,64)\n",
        "    X = layers.BatchNormalization()(X)\n",
        "    X = layers.ZeroPadding2D(padding=(4, 0))(X)\n",
        "    X = layers.Conv2D(filters=64, kernel_size=(9, 1), padding='valid', activation='relu', kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(X)\n",
        "    if add_dropout == True:\n",
        "        X = layers.Dropout(dropout_pct)(X)\n",
        "\n",
        "    Y = layers.Flatten()(X)\n",
        "\n",
        "    model = keras.Model(name = 'AtzoriNetDB2',\n",
        "                        inputs = X_inp,\n",
        "                        outputs = Y)\n",
        "\n",
        "    return model\n",
        "\n",
        "def AtzoriNetDB2_embedding_only_extra_layers_added(input_shape = (15,12,1), extra_layers=1, add_dropout = False, dropout_pct = 0.15, krnl_init_name = \"glorot_normal\", add_regularizer:bool = False, l2 = 0.0002):\n",
        "    # Kernel Initializer\n",
        "    if krnl_init_name == \"glorot_normal\":\n",
        "        kernel_init = initializers.glorot_normal(seed=0)\n",
        "    else:\n",
        "        kernel_init = initializers.glorot_uniform(seed=0)\n",
        "\n",
        "    if add_regularizer:\n",
        "        kernel_reg = regularizers.l2(l2)\n",
        "    else:\n",
        "        kernel_reg = None\n",
        "\n",
        "    # Input\n",
        "    X_inp = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Layer 1: Padding (0,5) -> Conv2D [32 x (1,12)] -> ReLU\n",
        "    # Input:  (15,12,1)\n",
        "    # Output: (15,11,32)\n",
        "    # X = layers.BatchNormalization(X_inp)\n",
        "    X = layers.BatchNormalization()(X_inp)\n",
        "    X = layers.ZeroPadding2D(padding=(0, 5))(X)\n",
        "    X = layers.Conv2D(filters=32, kernel_size=(1, 12), padding='valid', activation='relu', kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(X)\n",
        "    if add_dropout == True:\n",
        "        X = layers.Dropout(dropout_pct)(X)\n",
        "\n",
        "    # Layer 2: Padding (1,1) -> Conv2D [32 x (3,3)] -> ReLU -> AvgPooling(3,3)\n",
        "    # Input:  (15,11,32)\n",
        "    # Output: (5,3,32)\n",
        "    X = layers.BatchNormalization()(X)\n",
        "    X = layers.ZeroPadding2D(padding=(1, 1))(X)\n",
        "    X = layers.Conv2D(filters=32, kernel_size=(3, 3), padding='valid', activation='relu', kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(X)\n",
        "    if add_dropout == True:\n",
        "        X = layers.Dropout(dropout_pct)(X)\n",
        "    X = layers.AveragePooling2D(pool_size=(3, 3))(X)\n",
        "\n",
        "    # Extra layers\n",
        "    # Adding extra layers of 32 (3,3) filter with no Pooling\n",
        "    # Therefore the shape of the data does not change\n",
        "    # Input:  (5,3,32)\n",
        "    # Output: (5,3,32)\n",
        "    for i in range(extra_layers):\n",
        "        X = layers.BatchNormalization()(X)\n",
        "        X = layers.ZeroPadding2D(padding=(1, 1))(X)\n",
        "        X = layers.Conv2D(filters=32, kernel_size=(3, 3), padding='valid', activation='relu',\n",
        "                          kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(X)\n",
        "        if add_dropout == True:\n",
        "            X = layers.Dropout(dropout_pct)(X)\n",
        "\n",
        "\n",
        "    # Layer 3: Padding (2,2) -> Conv2D [64 x (5,5)] -> ReLU -> AvgPooling(3,3)\n",
        "    # Input:  (5,3,32)\n",
        "    # Output: (1,1,64)\n",
        "    X = layers.BatchNormalization()(X)\n",
        "    X = layers.ZeroPadding2D(padding=(2, 2))(X)\n",
        "    X = layers.Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu', kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(X)\n",
        "    if add_dropout == True:\n",
        "        X = layers.Dropout(dropout_pct)(X)\n",
        "    X = layers.AveragePooling2D(pool_size=(3, 3))(X)\n",
        "\n",
        "    # Layer 4: Padding (4,0) -> Conv2D [64 x (9,1)] -> ReLU\n",
        "    # The Output is a vector of length 64 corresponding to the input image\n",
        "    # Input:  (1,1,64)\n",
        "    # Output: (1,1,64)\n",
        "    X = layers.BatchNormalization()(X)\n",
        "    X = layers.ZeroPadding2D(padding=(4, 0))(X)\n",
        "    X = layers.Conv2D(filters=64, kernel_size=(9, 1), padding='valid', activation='relu', kernel_initializer=kernel_init, kernel_regularizer=kernel_reg)(X)\n",
        "    if add_dropout == True:\n",
        "        X = layers.Dropout(dropout_pct)(X)\n",
        "\n",
        "    Y = layers.Flatten()(X)\n",
        "    name = f'AtzoriNetDB2_{extra_layers}ExtraLayer'\n",
        "    if extra_layers > 1:\n",
        "        name += 's'\n",
        "\n",
        "    model = keras.Model(name = name,\n",
        "                        inputs = X_inp,\n",
        "                        outputs = Y)\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZKZPLpKgk3wa"
      },
      "outputs": [],
      "source": [
        "# @title fsl functions\n",
        "\n",
        "def produce_prototype(x):\n",
        "    return tf.reduce_mean(x,axis=-2)\n",
        "\n",
        "def reshape_query(x):\n",
        "    return tf.reshape(x,[-1,tf.shape(x)[-1]])\n",
        "\n",
        "def keep_first_tensor(x):\n",
        "    print_tensor_shape(x)\n",
        "    x = tf.expand_dims(x[0],axis=0)\n",
        "    print_tensor_shape(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def get_sum_of_squares(x):\n",
        "    return tf.reduce_sum(x**2,axis=1,keepdims=True)\n",
        "\n",
        "def euc_dist(args):\n",
        "    prototypes, query_feat = args\n",
        "\n",
        "    return tf.sqrt(tf.reduce_sum(tf.square(prototypes-query_feat), axis=-1))\n",
        "\n",
        "def l2_dist(args):\n",
        "    x1, x2 = args\n",
        "    return tf.square(x1-x2)\n",
        "\n",
        "def l1_dist(args):\n",
        "    x1, x2 = args\n",
        "    return tf.abs(x1-x2)\n",
        "\n",
        "def inner_product(args):\n",
        "    x1, x2 = args\n",
        "    return x1*x2\n",
        "\n",
        "def inner_product_norm(args):\n",
        "    x1, x2 = args\n",
        "    return (x1/tf.norm(x1))*(x2/tf.norm(x2))\n",
        "\n",
        "def inner_product_abs(args):\n",
        "    x1, x2 = args\n",
        "    return tf.abs(x1*x2)\n",
        "\n",
        "def inner_product_norm_abs(args):\n",
        "    x1, x2 = args\n",
        "    return tf.abs((x1/tf.norm(x1))*(x2/tf.norm(x2)))\n",
        "\n",
        "\n",
        "def softmax_classification(args, print_result=False):\n",
        "    pred = tf.nn.softmax(-euc_dist(args),axis=-1)\n",
        "    if print_result:\n",
        "        print_tensor(pred)\n",
        "    return pred\n",
        "\n",
        "def get_fsl_set_rand(N,k,dim1=28,dim2=28):\n",
        "    x = tf.random.uniform(shape=(N, k, dim1, dim2, 1), minval=0, maxval=1)\n",
        "    return x\n",
        "\n",
        "def get_fsl_set(x,N,k):\n",
        "    return tf.stack([tf.concat([i*x+j for j in range(k)],axis=0) for i in range(1,N+1)],axis=0)\n",
        "\n",
        "\n",
        "def print_tensor(tensor, precision=4):\n",
        "    tf.print(tf.strings.as_string(tensor,precision=precision))\n",
        "\n",
        "def print_tensor_shape(tensor):\n",
        "    tf.print(\"shape:\",tensor.shape)\n",
        "\n",
        "def reshape_query_set(layer_support_set_input, *args, **kwargs):\n",
        "  return tf.reshape(layer_support_set_input,[-1,way*shot]+list(inp_shape))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Jq2NsX51b9sv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Assemble Model\n",
        "def assemble_model_timeDist(nn_backbone, input_shape:tuple):\n",
        "    layer_time_dist = layers.TimeDistributed(nn_backbone, name=\"Time_Distributed\")\n",
        "\n",
        "    # tuple of 2d input set shape containing one extra dimension\n",
        "    input_shape_5d = (None,) + input_shape\n",
        "    layer_support_set_input = layers.Input(input_shape_5d, name=\"Support_Set_Input\")\n",
        "    layer_query_set_input = layers.Input(input_shape, name=\"Query_Set_Input\")\n",
        "\n",
        "    layer_support_set_embeddings = layer_time_dist(layer_support_set_input)\n",
        "    layer_prototypes = Lambda(produce_prototype,name=\"Prototypes\")(layer_support_set_embeddings)\n",
        "\n",
        "    layer_query_set_embedding = nn_backbone(layer_query_set_input)\n",
        "\n",
        "    layer_output_prediction = Lambda(softmax_classification, name=\"Prediction\")([layer_prototypes, layer_query_set_embedding])\n",
        "\n",
        "    model = keras.Model(inputs=[layer_support_set_input, layer_query_set_input], outputs=layer_output_prediction, name=\"Atzori_DB2_Protonet\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    Instead of adding a time-distributed layer in front of the cnn backbone to process 2d sets of data\n",
        "    it reshapes the support set into a 1d set. i.e. a (5,3) set of 15x12 images will be turned into a 5 x 3 = 15\n",
        "    images of size 15x12 and will all be processed simultaneously.\n",
        "    This will produces the 15 embeddings which will then be reshaped into the original 5x3 shape again\n",
        "\"\"\"\n",
        "def assemble_model_reshape(nn_backbone, input_shape:tuple, way:int, shot:int):\n",
        "    input_shape_5d = (None,) + input_shape\n",
        "    layer_support_set_input = layers.Input(input_shape_5d, name=\"Support_Set_Input\")\n",
        "    layer_query_set_input = layers.Input(input_shape, name=\"Query_Set_Input\")\n",
        "\n",
        "    # Concatenate the support set and query image into a 1d set of the standard input shape.\n",
        "    # i.e. a (3,2) support set and 1 query image of size (15,12,1) will form a set of 2x3+1 = 7 images (15,12,1)\n",
        "    layer_support_query_concat = tf.concat([tf.reshape(layer_support_set_input,[way*shot]+list(input_shape)), layer_query_set_input],axis=0)\n",
        "\n",
        "    # We Produce Embeddings for all input data (support and query) by passing them all together through the network in feed forward fashion\n",
        "    # Based on the previous example, given that a (15,12,1) image produces a (64,) long embedding, the whole\n",
        "    # reshaped (7,15,12,1) set should produce a (7,64) set of embeddings\n",
        "    layer_support_query_embeddings = nn_backbone(layer_support_query_concat)\n",
        "\n",
        "    # Separate quary and support embeddings\n",
        "    # Separate and reshape support set embeddings (6,64) -> (3,2,64)\n",
        "    layer_support_set_embeddings = tf.reshape(layer_support_query_embeddings[:way*shot],[way,shot,layer_support_query_embeddings.shape[1]])\n",
        "    layer_query_set_embedding = layer_support_query_embeddings[way*shot:]\n",
        "\n",
        "    # Produce the prototypes of the support set\n",
        "    # This should reduce the support set embeddings down to: (3,2,64) -> (3,64) by averaging the 2 embeddings of each of the 3 classes\n",
        "    layer_prototypes = Lambda(produce_prototype)(layer_support_set_embeddings)\n",
        "\n",
        "    # Make final prediction\n",
        "    layer_prediction = Lambda(softmax_classification)([layer_prototypes, layer_query_set_embedding])\n",
        "\n",
        "    # Assemble the final Model\n",
        "    model = keras.Model(inputs = [layer_support_set_input, layer_query_set_input], outputs=layer_prediction)\n",
        "\n",
        "    return model\n",
        "\n",
        "def assemble_protonet_reshape_with_batch(nn_backbone, input_shape:tuple, way:int, shot:int):\n",
        "    input_shape_4d = (1,) + input_shape\n",
        "    input_shape_5d = (None,None,) + input_shape\n",
        "    layer_support_set_input = layers.Input(input_shape_5d, name=\"Support_Set_Input\")\n",
        "    layer_query_set_input = layers.Input(input_shape_4d, name=\"Query_Set_Input\")\n",
        "\n",
        "    nn_backbone_timeDist = layers.TimeDistributed(nn_backbone)\n",
        "\n",
        "    # Concatenate the support set and query image into a 1d set of the standard input shape.\n",
        "    # i.e. a (3,2) support set and 1 query image of size (15,12,1) will form a set of 2x3+1 = 7 images (15,12,1)\n",
        "    layer_support_query_concat = tf.concat([tf.reshape(layer_support_set_input,[-1,way*shot]+list(input_shape)), layer_query_set_input],axis=1)\n",
        "\n",
        "    # We Produce Embeddings for all input data (support and query) by passing them all together through the network in feed forward fashion\n",
        "    # Based on the previous example, given that a (15,12,1) image produces a (64,1) embedding, the whole\n",
        "    # reshaped (7,15,12,1) set should produce a (7,64,1) set of embeddings\n",
        "    layer_support_query_embeddings = nn_backbone_timeDist(layer_support_query_concat)\n",
        "\n",
        "    # Separate query and support embeddings\n",
        "    # Separate and reshape support set embeddings (6,64,1) -> (3,2,64,1)\n",
        "    layer_support_set_embeddings = tf.reshape(layer_support_query_embeddings[:,:way * shot], [-1,way, shot, layer_support_query_embeddings.shape[-1]])\n",
        "    layer_query_set_embedding = layer_support_query_embeddings[:,way*shot:]\n",
        "\n",
        "    # Produce the prototypes of the support set\n",
        "    # This should reduce the support set embeddings down to: (3,2,64,1) -> (3,64,1) by averaging the 2 embeddings of each of the 3 classes\n",
        "    layer_prototypes = layers.Lambda(produce_prototype)(layer_support_set_embeddings)\n",
        "\n",
        "    # Make final prediction\n",
        "    layer_prediction = layers.Lambda(softmax_classification)([layer_prototypes, layer_query_set_embedding])\n",
        "\n",
        "    # Assemble the final Model\n",
        "    model = keras.Model(inputs = [layer_support_set_input, layer_query_set_input], outputs=layer_prediction, name=\"ProtoNet\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    Returns a set of fully connected layers, each with the number of neurons defined by a list parameter.\n",
        "    Last layer is a single neuron layer providing a scalar output\n",
        "    Each layer has a relu activation function except for the last which has a sigmoid (for providing a normalized output between 0.0 and 1.0)\n",
        "\n",
        "PARAMETERS\n",
        "    - neurons_per_layer = [128,64] would mean 2 layers of 128 and 64 neurons etc before the single neuron output\n",
        "\"\"\"\n",
        "def get_dense_layers(neurons_per_layer=[]):\n",
        "    dense_layers = keras.Sequential()\n",
        "    for i,neurons_number in enumerate(neurons_per_layer):\n",
        "        dense_layers.add(layers.BatchNormalization())\n",
        "        dense_layers.add(layers.Dense(units=neurons_number,activation='relu',name=f\"dense_layer_{i+1}\"))\n",
        "    dense_layers.add(layers.Dense(units=1,activation='sigmoid', name=f\"prediction_dense_layer\"))\n",
        "\n",
        "    return dense_layers\n",
        "\n",
        "\n",
        "class SiameseNetwork(keras.Model):\n",
        "    def __init__(self,cnn_backbone:keras.Model,f,inp_shape:tuple, dense_layers):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.feature_extractor = cnn_backbone\n",
        "        self.f = f\n",
        "        self.inp_shape = inp_shape\n",
        "\n",
        "        self.dense_layers = dense_layers\n",
        "\n",
        "        return\n",
        "\n",
        "    def call(self, input):\n",
        "        x1,x2 = input\n",
        "\n",
        "        embedding1 = self.feature_extractor(x1)\n",
        "        embedding2 = self.feature_extractor(x2)\n",
        "\n",
        "        embedding_dist = self.f([embedding1,embedding2])\n",
        "\n",
        "        similarity_score = self.dense_layers(embedding_dist)\n",
        "\n",
        "        return similarity_score\n",
        "\n",
        "\n",
        "def assemble_siamNet_for_few_shot_infernce(model,inp_shape,N):\n",
        "    feature_extractor = model.feature_extractor\n",
        "    dense_layers = model.dense_layers\n",
        "    f = model.f\n",
        "\n",
        "    input_shape_4d = (1,) + inp_shape\n",
        "    input_shape_5d = (None, None,) + inp_shape\n",
        "    layer_support_set_input = layers.Input(input_shape_5d, name=\"Support_Set_Input\")\n",
        "    layer_query_set_input = layers.Input(input_shape_4d, name=\"Query_Set_Input\")\n",
        "\n",
        "    feature_extractor_timeDist = TimeDistributed(feature_extractor)\n",
        "    feature_extractor_timeDist_support = TimeDistributed(feature_extractor_timeDist)\n",
        "\n",
        "    layer_support_embeddings = feature_extractor_timeDist_support(layer_support_set_input)\n",
        "    layer_query_embedding = feature_extractor_timeDist(layer_query_set_input)\n",
        "\n",
        "    layer_support_set_prototypes = produce_prototype(layer_support_embeddings)\n",
        "    layer_query_embedding_copied = tf.tile(layer_query_embedding, [1, N, 1])\n",
        "\n",
        "    layer_dist_func = f([layer_support_set_prototypes, layer_query_embedding_copied])\n",
        "\n",
        "    pred = TimeDistributed(dense_layers)(layer_dist_func)\n",
        "\n",
        "    model_val = keras.Model(inputs=[layer_support_set_input, layer_query_set_input], outputs=pred)\n",
        "\n",
        "    return model_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTnhhqbUxBz7"
      },
      "source": [
        "# 3 - USEFUL FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "gU4C3DnQVPg6"
      },
      "outputs": [],
      "source": [
        "# @title helper functions\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    Gets a list of keys (ie ['s1g1r3','s12g23r2','s12g40r1'] and returns the unique\n",
        "    s,g,r values of all keys.\n",
        "    In this example th unique subjects are 1,12, the unique gestures are 1,23,40\n",
        "    and the unique reps are 1,2,3.\n",
        "    Therefore the returning values are the following arrays:\n",
        "    array([ 1, 12]), array([ 1, 23, 40]), array([1, 2, 3])\n",
        "\"\"\"\n",
        "def get_unique_sgr(keylist):\n",
        "    pattern = r'\\d+\\.?\\d*'\n",
        "    sgr_list = np.array([[int(i) for i in re.findall(pattern, key)] for key in keylist])\n",
        "    s = np.unique(sgr_list[:,0])\n",
        "    g = np.unique(sgr_list[:,1])\n",
        "    r = np.unique(sgr_list[:,2])\n",
        "\n",
        "    return s,g,r\n",
        "\n",
        "\"\"\"\n",
        "Prints the keys of the support and query sets of a specific task in a formatted way\n",
        "i.e. |  s1g1r3  s2g5r4  s12g7r3 |\n",
        "     | s14g1r5  s5g5r1  s9g7r1  |\n",
        "\n",
        "\"\"\"\n",
        "def printKeys(keys):\n",
        "    print()\n",
        "    for j in range(len(keys[0])):\n",
        "        print(\"| |\", end='')\n",
        "        for i in range(len(keys)):\n",
        "            # Key takes up 8 cells of space\n",
        "            print(keys[i][j],end=\"| |\")\n",
        "        print()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    For changing the formatting of the s,g,r values into the key String so that each int takes\n",
        "    up 2 digits regardless of value\n",
        "    ie : 's1g12r4' -> 's01g12r04'\n",
        "    That way keys can also be easily sorted\n",
        "\n",
        "PARAMETERS\n",
        "    Key in old format ('s1g12r4')\n",
        "\n",
        "OUTPUT\n",
        "    Newly formatted key ('s01g12r04')\n",
        "\"\"\"\n",
        "def reformat_key(key):\n",
        "    pattern = r'\\d+\\.?\\d*'\n",
        "    s,g,r = [int(i) for i in re.findall(pattern, key)]\n",
        "    new_key = f\"s{s:02d}g{g:02d}r{r:02d}\"\n",
        "    return new_key\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    For getting a key based on given s,g,r values using the new format (2 digits regardless of value)\n",
        "\"\"\"\n",
        "def getKey(s,g,r):\n",
        "    return f\"s{s:02d}g{g:02d}r{r:02d}\"\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    Returns the name of the directory containing data of a certain database (db2 mainly) which are\n",
        "    rms rectified (created offline) with a certain window size (in ms)\n",
        "    i.e. 'db2_rms_100'\n",
        "\"\"\"\n",
        "def get_rms_rect_filename(db, win_size_ms):\n",
        "    return f\"db{db}_rms_{win_size_ms}.npz\"\n",
        "\n",
        "def get_rms_sub_filename(db, win_size_ms,new_freq):\n",
        "    return f\"db{db}_rms_{win_size_ms}_sub_{new_freq}.npz\"\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    For getting the full name of a configuration .json file (either for preprocessing, augmentation or training).\n",
        "    depending on the mode the full filename is \"config_{mode}_{filename}.json where filename usually includes info\n",
        "    regarding the database if it is referring to a specific one\n",
        "\n",
        "PARAMETERS\n",
        "    mode : \"preproc\", \"aug\" or \"train\"\n",
        "\"\"\"\n",
        "def get_config_full_filename(mode, name):\n",
        "    return f\"config_{mode}_{name}.json\"\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    Loads and returns configuration data for either preprocessing, augmentation or training.\n",
        "    Data is in the form of a jason file and the returning value is a dict\n",
        "\n",
        "PARAMETERS\n",
        "    mode : \"preproc\", \"aug\" or \"train\"\n",
        "    filename : name of the file without the 'config_preproc' prefix of the '.json' postfix\n",
        "\"\"\"\n",
        "def get_config_from_json_file(mode, filename):\n",
        "    full_filename = get_config_full_filename(mode, filename)\n",
        "    if mode == \"preproc\":\n",
        "        dir_path = DATA_CONFIG_PATH_PREPROC\n",
        "    elif mode == \"aug\" :\n",
        "        dir_path = DATA_CONFIG_PATH_AUG\n",
        "    elif mode == \"train\" :\n",
        "        return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    with open(os.path.join(dir_path,full_filename)) as file:\n",
        "        config = json.load(file)\n",
        "        return config\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    Returns the full filename of the .csv file where all the tasks for a given experiment exist\n",
        "    It is something along the lines of ex{experiment}_{N}way_{k}shot.csv\n",
        "    For the full path the FileInfoProvider in TaskGenerator takes care of it\n",
        "\n",
        "PARAMETERS\n",
        "    - mode : 'train', 'test' or 'val'\n",
        "\"\"\"\n",
        "def get_tasks_filename(ex,N,k, mode):\n",
        "    return f'ex{ex}_{N}way_{k}shot_{mode}.csv'\n",
        "\n",
        "def get_results_dir_fullpath(ex : str, N:int, k:int):\n",
        "    return os.path.join(RESULTS_DIRECTORIES_DICT[ex],f'{N}_way_{k}_shot')\n",
        "\n",
        "\"\"\"\n",
        "    DESCRIPTION\n",
        "    Determines the name of the model based on the number of existing models of the same type.\n",
        "    i.e. it could be a protoNet with different backbone each time. It creates a file with the correct enumeration\n",
        "    based on the number of existing models of that type.\n",
        "\n",
        "    For example if there are already models 'model_protoNet_1.h5' and 'model_protoNet_2.h5' the file will be named\n",
        "    'model_protoNet_3.h5' etc. If there are none the number will be set to '1'\n",
        "\n",
        "    To provide mode info for the model and the training process in general a .txt file wll be provided\n",
        "\"\"\"\n",
        "def get_checkpoint_foldername(dir_path, model_name):\n",
        "    name = f\"model_{model_name}_1\"\n",
        "    while name in os.listdir(dir_path):\n",
        "        num = int((name.split('.')[0]).split('_')[-1])\n",
        "        name = f\"model_{model_name}_{num + 1}\"\n",
        "    return name\n",
        "\n",
        "\"\"\"\n",
        "PARAMETERS\n",
        "    criterion: 'latest', 'best_loss' or 'best_acc'\n",
        "\"\"\"\n",
        "def get_model_checkpoint_fullname(model_name, criterion):\n",
        "    if criterion == 'latest':\n",
        "        return model_name + '.h5'\n",
        "    elif criterion == 'best_loss':\n",
        "        return model_name + '_best_loss' + '.h5'\n",
        "    elif criterion == 'best_acc':\n",
        "        return model_name + '_best_acc' + '.h5'\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    Takes as input a line in the form \"7    \t0.3781         \t1.4724         \t0.3410         \t1.6121\"\n",
        "    and returns 7\n",
        "\"\"\"\n",
        "def get_line_starting_number(line):\n",
        "    i=0\n",
        "    while line[i].isdigit():\n",
        "        i+=1\n",
        "\n",
        "    return int(line[:i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "d2vAm_RLxUR0"
      },
      "outputs": [],
      "source": [
        "# @title plot functions\n",
        "\n",
        "def plot_sEMG(emg, fs, channels=[1,2,3,4,5,6], title='', figure_name = 'Figure', export=False, filename=''):\n",
        "  fig = plt.figure()\n",
        "  fig.canvas.manager.set_window_title(figure_name)\n",
        "\n",
        "  time = np.arange(len(emg))\n",
        "  time = time/fs\n",
        "  N = len(channels)\n",
        "\n",
        "  for i in range(N):\n",
        "    emg_channel = emg[:,channels[i]-1]\n",
        "    max = np.max(np.abs(emg_channel))\n",
        "    emg_norm = emg_channel/max\n",
        "    offset = 2.5*(N-i-1)\n",
        "    plt.plot(time,emg_norm+offset, label='channel {}'.format(i+1))\n",
        "\n",
        "  lgd = plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
        "  plt.xlabel('time')\n",
        "  plt.ylabel('channels')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"\n",
        "    DESCRIPTION\n",
        "    Plots the spectrum of a 1-d channel of an semg signal\n",
        "    If the all the channels of the signal are inserted it keeps the first one\n",
        "    It shows the spectrum Amplitude for frequencies up to fs/2, either in multiples of pi or in Hz\n",
        "\n",
        "    PARAMETERS\n",
        "    x   : the semg signal channel\n",
        "    fs  : sampling frequency\n",
        "    title : plot title\n",
        "    figure_name : name for the figure that will be initialized\n",
        "\n",
        "    RETURNS\n",
        "    Nothing\n",
        "\"\"\"\n",
        "def plotSpectrum(x,fs,showInMultiplesOfPi=False, title='Φάσμα emg σήματος', figure_name='Spectrum of sEMG Channel'):\n",
        "  fig = plt.figure()\n",
        "  fig.canvas.manager.set_window_title(figure_name)\n",
        "\n",
        "  if(len(x.shape)>1):\n",
        "    x = x[:,0]\n",
        "\n",
        "  X = fft(x,5*len(x))\n",
        "  L = len(X)\n",
        "  L_lim = L//2\n",
        "  if showInMultiplesOfPi:\n",
        "    freq_lim = 1\n",
        "    x_text = \"Digital Frequency in multiples of pi\"\n",
        "  else:\n",
        "    freq_lim = fs/2\n",
        "    x_text = \"Analog Frequency in Hz ([0,Fs/2])\"\n",
        "\n",
        "  df = freq_lim/(L_lim)\n",
        "\n",
        "  freq = np.arange(0,freq_lim,df)\n",
        "  magnitude = np.abs(X)[:L_lim]\n",
        "  plt.plot(freq, magnitude,color='r',label='sEMG Spectrum')\n",
        "\n",
        "  plt.xlabel(x_text)\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "  return\n",
        "\n",
        "\"\"\"\n",
        "DECRIPTION\n",
        "  For plotting the values of a dictionary using a bar\n",
        "  If keys have multiple values (same number of values for each key) they will be displayed using multiple colors (same for each category)\n",
        "\n",
        "PARAMETERS\n",
        "  data_dict : dictionary whose values are either lists (of same nuber of elements) or 1 value\n",
        "  i.e. data_dict = {\n",
        "        'a': [3, 4, 3],\n",
        "        'b': [5, 7, 3],\n",
        "        'c': [2, 2, 3]\n",
        "      }\n",
        "\"\"\"\n",
        "def plotDictBar(data_dict:dict):\n",
        "  total_bars = 100\n",
        "  start = (27*49-10)*6\n",
        "  ind = list(range(start,start+total_bars))\n",
        "  keys = list(data_dict.keys())[start:start+total_bars]\n",
        "  values = np.array(list(data_dict.values()))[start:start+total_bars]\n",
        "\n",
        "  # Number of categories\n",
        "  num_categories = values.shape[1]\n",
        "\n",
        "  # Colors for each category\n",
        "  colors = plt.cm.viridis(np.linspace(0, 1, num_categories))\n",
        "\n",
        "  # Create a stacked bar chart\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  # Plot each category\n",
        "  for i in range(num_categories):\n",
        "    if i == 0:\n",
        "      ax.bar(keys, values[:, i], color=colors[i], label=f'non-augmented')\n",
        "    else:\n",
        "      ax.bar(keys, values[:, i], bottom=np.sum(values[:, :i], axis=1), color=colors[i], label=f'augmented')\n",
        "\n",
        "  plt.xlabel('Key')\n",
        "  plt.ylabel('Value')\n",
        "\n",
        "  # Add a legend\n",
        "  plt.legend()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "  return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMNeTAUuwzW3"
      },
      "source": [
        "# 4 - DATA PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hVksTSPrSrvo"
      },
      "outputs": [],
      "source": [
        "# @title Preprocessing\n",
        "\n",
        "def get_segmentation_indices(x: np.ndarray, window_size_ms: int, window_step_ms: int, fs):\n",
        "    window_size = int((window_size_ms * fs) / 1000)\n",
        "    window_step = int((window_step_ms * fs) / 1000)\n",
        "    slice_start_indices = np.arange(0, len(x) - window_size + 1, window_step)\n",
        "    return slice_start_indices\n",
        "\n",
        "\n",
        "def subsample(x: np.ndarray, init_freq: float, new_freq: float):\n",
        "    sub_factor = int(init_freq / new_freq)\n",
        "    indices = np.arange(0, len(x), sub_factor)\n",
        "    return np.take(x, indices=indices, axis=0)\n",
        "\n",
        "def get_filter_coeffs(fc=1, fs=100, N=1):\n",
        "    f = 2 * fc / fs\n",
        "    b, a = scipy.signal.butter(N=N, Wn=f, btype='low')\n",
        "\n",
        "    return b,a\n",
        "\n",
        "def applyLPFilter(x, b ,a):\n",
        "    x = np.abs(x)\n",
        "    output = scipy.signal.filtfilt(b, a, x, axis=0, padtype='odd', padlen=3 * (max(len(b), len(a)) - 1))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def applyLPFilter2(emg, fc=1, fs=100, N=1):\n",
        "    f_sos = scipy.signal.butter(N=N, Wn=2 * fc / fs, btype='low', output='sos')\n",
        "    return scipy.signal.sosfilt(f_sos, emg, axis=0)\n",
        "\n",
        "def minmax_norm(x):\n",
        "    max_x = np.max(x)\n",
        "    min_x = np.min(x)\n",
        "    return (x-min_x) / (max_x-min_x)\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    Performs μ-Law on a given emg signal x for a given value of μ\n",
        "PARAMETERS\n",
        "    - χ: The emg signal\n",
        "    - μ: The value used n the formula\n",
        "    - scaling_type: \"all\" for scaling all channels with the absolute maximum of the while signal\n",
        "                    \"each\" for scaling with the maximum of each channel\n",
        "\"\"\"\n",
        "def muLaw_transform(x, mu = 2048, scaling_type = \"all\"):\n",
        "\n",
        "    if scaling_type == \"each\":\n",
        "        x = x/np.max(np.abs(x),axis=0)\n",
        "    else:\n",
        "        x= x/np.max(np.abs(x))\n",
        "\n",
        "    return np.sign(x)*(np.log(1+mu*np.abs(x))/np.log(1+mu))\n",
        "\n",
        "\n",
        "# Keeps only a certain amount of samples from each emg, the middle seconds_to_keep ones\n",
        "def discard_early_and_late_gest_stages(x, seconds_to_keep, fs):\n",
        "    num_samples_to_keep = int(seconds_to_keep*fs)\n",
        "    # Half the length of samples to keep\n",
        "    W = num_samples_to_keep // 2\n",
        "    L = len(x)\n",
        "    return x[max(L // 2 - W, 0):min(L // 2 + W, L)]\n",
        "\n",
        "\n",
        "def apply_preprocessing(data_path, key_list, final_sample_subfix, total_subjects, config_dict:dict):\n",
        "    print(\"Data processing...\")\n",
        "    print(\"...loading the data...\")\n",
        "    all_data = np.load(data_path)\n",
        "    data = {key:all_data[key] for key in key_list}\n",
        "    data_proc = {key:None for key in data}\n",
        "    data_seg = {key:None for key in data}\n",
        "\n",
        "    config_operations = config_dict['ops'].copy()\n",
        "    config_params = config_dict['params'].copy()\n",
        "    op_no_seg = [op for op in preprocess_operations if not op == \"SEGMENT\"]\n",
        "\n",
        "    if config_operations[\"LOWPASS\"] == True :\n",
        "        b, a = get_filter_coeffs(**config_params[\"LOWPASS\"])\n",
        "        config_params[\"LOWPASS\"] = {\"b\" : b, \"a\" : a}\n",
        "\n",
        "    operations_params = [(preprocess_funcs[op], config_params[op]) for op in preprocess_operations if\n",
        "                         config_operations[op] == True and op != \"SEGMENT\"]\n",
        "\n",
        "    progress_bar = tqdm(total=total_subjects, desc=\"Preprocessing\", unit=\" reps\")\n",
        "    subjects_completed = 0\n",
        "    t1 = time.time()\n",
        "    for key, emg in data.items():\n",
        "        # for testing purposes\n",
        "        # for op in op_no_seg:\n",
        "        # if key == \"s12g34r04\":\n",
        "        #     print()\n",
        "        for func, params in operations_params:\n",
        "            emg = func(emg, **params)\n",
        "\n",
        "        data_proc[key] = np.expand_dims(emg, -1)\n",
        "\n",
        "        if key[3:] == final_sample_subfix:\n",
        "            subjects_completed += 1\n",
        "            progress_bar.set_postfix(subject=f'{key[:3]}')\n",
        "            progress_bar.update(1)  # Update progress bar by 1\n",
        "            # print(f\"{key[:3]} ({subjects_completed}/{total_subjects})\")\n",
        "            t1 = time.time()\n",
        "\n",
        "    if config_operations[\"SEGMENT\"] == True:\n",
        "        for key, emg in data_proc.items():\n",
        "            data_seg[key] = get_segmentation_indices(emg, **config_params[\"SEGMENT\"])\n",
        "    progress_bar.close()\n",
        "\n",
        "    return data_proc, data_seg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "preprocess_operations = [\"SUBSAMPLE\", \"DISCARD\", \"LOWPASS\", \"M-LAW\", \"MIN-MAX\", \"SEGMENT\"]\n",
        "\n",
        "preprocess_funcs = {\n",
        "    \"DISCARD\"   :   discard_early_and_late_gest_stages,\n",
        "    \"SUBSAMPLE\" :   subsample,\n",
        "    \"LOWPASS\"   :   applyLPFilter,\n",
        "    \"M-LAW\"     :   muLaw_transform,\n",
        "    \"MIN-MAX\"   :   minmax_norm,\n",
        "    \"SEGMENT\"   :   get_segmentation_indices\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "dnJoElTPyzwy"
      },
      "outputs": [],
      "source": [
        "# @title RMS Rectification\n",
        "\n",
        "def calculate_total_size(data_rms:dict):\n",
        "    total_size = 0\n",
        "    # Total size in bytes\n",
        "    for key,emg in data_rms.items():\n",
        "        total_size += emg.nbytes\n",
        "    # size in giga bytes\n",
        "    total_size/=(2**30)\n",
        "    print(f\"Total size: {total_size:.1f}Gb\")\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    For saving the dict of existing rms-rectified signals in the given path.\n",
        "    Takes into account that the dict containing the rectified data, has all the possible\n",
        "    keys for the specific database but not all data have been rectified, and so some values\n",
        "    for specific keys are None.\n",
        "    If no rectification has been done and no folder exists, it creates one based on the given name\n",
        "\"\"\"\n",
        "def save_rectified_gestures(data_rms: dict, full_path: str, filename:str):\n",
        "    # Keeps only the non None values\n",
        "    data_rms = {key: data_rms[key] for key in data_rms if data_rms[key] is not None}\n",
        "\n",
        "    full_file_path = os.path.join(full_path,filename)\n",
        "    np.savez(full_file_path, **data_rms)\n",
        "    print(f\"Rectified data saved at: '{full_file_path}'\")\n",
        "    calculate_total_size(data_rms)\n",
        "    return\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "    Faster version for performing RMS Rectification on emg data\n",
        "    Instead of calculating sum of squares over a given time window it calculates the squares and their\n",
        "    cumulative sum beforehand and saves it in the emg_pad_csum array. That way emg_pad_csum[i] consists\n",
        "    of the sum of all squares up to the i-th element in the original emg recording. Therefore, to calculate\n",
        "    the sum of squares over a window (which covers the indices from i to j) all you need to do is calculate\n",
        "    the difference between emg_pad_csum[j] and emg_pad_csum[i-1].\n",
        "\n",
        "PARAMETERS\n",
        "    x: emg recording to be rectified\n",
        "    fs: sampling rate (2000 for DB2)\n",
        "    win_size_ms: window size in milliseconds\n",
        "\"\"\"\n",
        "def rmsRect(x:np.ndarray, fs = 2000, win_size_ms=200):\n",
        "    emg_rect = np.zeros(x.shape)\n",
        "    W = int(win_size_ms*fs/1000)\n",
        "\n",
        "    # npad: window_length/2 (used later for padding)\n",
        "    npad = np.floor(W / 2).astype(int)\n",
        "    win = int(W)\n",
        "\n",
        "    # Symmetric padding with half the length of the window from each side\n",
        "    # Thus ensuring the sliding window won't affect the total signal length\n",
        "    # i.e. for x = [0,1,2,3,4,5,6,7] and W/2 == 3 symmetric padding should be\n",
        "    #        [2,1,0,0,1,2,3,4,5,6,7,7,6,5]\n",
        "    emg_pad = np.pad(x, ((npad, npad), (0, 0)), 'symmetric')\n",
        "\n",
        "    # Square values of all cells\n",
        "    emg_pad_squared = emg_pad**2\n",
        "    # Cumulative sum along the time axis (where emg_pad_csum[i] = sum(emg_pad_squared[:i] for each channel)\n",
        "    emg_pad_csum = np.cumsum(emg_pad_squared,axis=0)\n",
        "\n",
        "    # emg[i] is replaced by the rms value of all the samples contained by the sliding window\n",
        "    # centered in position i\n",
        "    emg_pad_csum = np.pad(emg_pad_csum,((1,0),(0,0)) ,mode='constant', constant_values=0)\n",
        "\n",
        "    emg_rect = np.sqrt((emg_pad_csum[win:-1]-emg_pad_csum[:-win-1])/win)\n",
        "    return emg_rect\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DESCRIPTION\n",
        "\n",
        "PARAMETERS\n",
        "    db_dir_path:    full path of the directory where the data of the database in question exist\n",
        "                    ie 'C:\\\\Users\\\\ΤΑΣΟΣ\\\\Desktop\\\\Σχολή\\\\Διπλωματική\\\\Δεδομένα\\\\processed\\\\db2'\n",
        "\"\"\"\n",
        "def apply_rms_rect(db: int, db_dir_path: str, fs: int, win_size_ms: int):\n",
        "    rms_filename = get_rms_rect_filename(db, win_size_ms)  # ie 'db2_rms_100.npz'\n",
        "    full_rms_file_path = os.path.join(db_dir_path, rms_filename)\n",
        "    # rms_filename = rms_dir_name + '.npz'\n",
        "\n",
        "    separated_data_filename = os.path.join(SEPARATED_DATA_PATH, f'db{db}.npz')\n",
        "    data_sep_raw = np.load(separated_data_filename)\n",
        "\n",
        "    already_rectified = 0\n",
        "\n",
        "    # Case where the folder exists (and thus the rectification has either been completed or at least partially done\n",
        "    if rms_filename in os.listdir(db_dir_path):\n",
        "        # Checking whether all gestures have been rectified\n",
        "        data_rms = np.load(full_rms_file_path)\n",
        "\n",
        "        # If all the keys exist in the file, then rms rectification with that specific window size has already been doneand there is no need to redo\n",
        "        if (set(data_rms.files) == set(data_sep_raw.files)):\n",
        "            print(\"RMS Rectification with that window size already exists\")\n",
        "            return\n",
        "        already_rectified = len(data_rms.files)\n",
        "        remaining_keys = sorted(list(set(data_sep_raw.files) - set(data_rms.files)))\n",
        "        # Copying all values of already rectified gestures to the corresponding keys in data_rms dict\n",
        "        data_rms = {key: data_rms[key] for key in data_rms.files}\n",
        "        # Initializing values for all keys of non-rectified gestures\n",
        "        for key in remaining_keys:\n",
        "            data_rms[key] = None\n",
        "\n",
        "    else:\n",
        "        remaining_keys = data_sep_raw.files\n",
        "        # Initializing values for all keys to None\n",
        "        data_rms = {key: None for key in remaining_keys}\n",
        "\n",
        "    total_keys = len(remaining_keys) + already_rectified\n",
        "    t_start = time.time()\n",
        "    t1 = time.time()\n",
        "    for i, key in enumerate(remaining_keys):\n",
        "        emg = data_sep_raw[key]\n",
        "        emg_rms = rmsRect(emg, win_size_ms=win_size_ms, fs=fs)\n",
        "\n",
        "        data_rms[key] = np.copy(emg_rms)\n",
        "        if (key[3:] == 'g49r06'):\n",
        "            time_for_subject = time.time() - t1\n",
        "            print(f\"subject '{key[:3]}' ({already_rectified + i + 1}/{total_keys}) - {time_for_subject:.2f}s\")\n",
        "            t1 = time.time()\n",
        "\n",
        "    print(\"total_time:\", time.time() - t_start)\n",
        "    save_rectified_gestures(data_rms, full_path=db_dir_path, filename=rms_filename)\n",
        "\n",
        "    return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "wDJw3CDYUIAM"
      },
      "outputs": [],
      "source": [
        "# @title Augmentation\n",
        "\n",
        "def addGaussianNoise(emg:np.ndarray, snr_db:int = 25):\n",
        "    # reduce dimension (time,channels,1) -> (time,channels)\n",
        "    # i.e. (740,12,1) -> (740,12)\n",
        "    emg = np.squeeze(emg)\n",
        "\n",
        "    # provides the mean square value (power) along each channels\n",
        "    # Should return a (1,channels) sized output where each element is the mean square value of each channel\n",
        "    emg_mean_square = np.mean(emg**2, axis=0,keepdims=True)\n",
        "\n",
        "    # SNR from db to linear value\n",
        "    snr = 10 ** (snr_db/10)\n",
        "\n",
        "    # Gaussian noise power (variance)\n",
        "    noise_power = emg_mean_square/snr\n",
        "    # stdev should be a (1,channels) array where each value is the stdev of the awgn for the respective channel\n",
        "    stdev = np.sqrt(noise_power)\n",
        "\n",
        "    # Gaussian Noise creation with 0 mean and the stdev we computed earlier\n",
        "    awgn = np.random.normal(size=emg.shape, scale=stdev, loc=0.0)\n",
        "    emg_n = emg + awgn\n",
        "\n",
        "    return np.expand_dims(emg_n,-1)\n",
        "\n",
        "def apply_augmentation(data, config_dict:dict, final_sample_subfix, total_subjects):\n",
        "    print(\"Performing Data Augmentation...\")\n",
        "    data_aug = {key: None for key in data}\n",
        "    ops = config_dict['ops']\n",
        "    params = config_dict['params']\n",
        "\n",
        "    progress_bar = tqdm(total=total_subjects, desc=\"Augmentation\", unit=\" reps\")\n",
        "    subjects_completed = 0\n",
        "    t1 = time.time()\n",
        "    for key,emg in data.items():\n",
        "\n",
        "        for op in [op for op in augmentation_operations if ops[op] == True]:\n",
        "            emg = augmentation_funcs[op](emg, **params[op])\n",
        "        data_aug[key] = np.copy(emg)\n",
        "\n",
        "        if key[3:] == final_sample_subfix :\n",
        "            subjects_completed += 1\n",
        "            progress_bar.set_postfix(subject=f'{key[:3]}')\n",
        "            progress_bar.update(1)  # Update progress bar by 1\n",
        "            # print(f\"{key[:3]} ({subjects_completed}/{total_subjects}) : {time.time()-t1:.2f}s\")\n",
        "            t1 = time.time()\n",
        "\n",
        "    progress_bar.close()\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return data_aug\n",
        "\n",
        "\n",
        "\n",
        "augmentation_operations = [\"AWGN\", \"FLIP\"]\n",
        "augmentation_funcs = {\n",
        "    \"AWGN\" : addGaussianNoise,\n",
        "    \"FLIP\" : None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvdh4n69F91d"
      },
      "source": [
        "# 5 - CREATE RMS AND SUBSAMPLING FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IRwO-L6Oggis"
      },
      "outputs": [],
      "source": [
        "# @title Create RMS Rect\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    db = 2\n",
        "    fs = 2000\n",
        "    win_size_ms = 150\n",
        "\n",
        "    if db == 1:\n",
        "        path = PROCESSED_DATA_PATH_DB1\n",
        "    elif db == 2:\n",
        "        path = RMS_DATA_PATH_DB2\n",
        "    elif db == 5:\n",
        "        path = PROCESSED_DATA_PATH_DB5\n",
        "    else:\n",
        "        exit(0)\n",
        "\n",
        "    apply_rms_rect(db=db, db_dir_path=path, fs=fs, win_size_ms=win_size_ms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "grX7xhO9-eFa",
        "outputId": "4a24f1c3-698f-45d8-e9f0-badf0dd42de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "RMS Rectification for 150ms window size\n",
            "\n",
            "s01: 0.5368850231170654s\n",
            "s02: 1.0624680519104004s\n",
            "s03: 1.6341922283172607s\n",
            "s04: 2.3194808959960938s\n",
            "s05: 2.8272173404693604s\n",
            "s06: 3.3382062911987305s\n",
            "s07: 4.001087665557861s\n",
            "s08: 4.513712406158447s\n",
            "s09: 5.096949577331543s\n",
            "s10: 5.724949598312378s\n",
            "s11: 6.416332006454468s\n",
            "s12: 6.996959686279297s\n",
            "s13: 7.469321250915527s\n",
            "s14: 8.124029159545898s\n",
            "s15: 8.664900779724121s\n",
            "s16: 9.228147506713867s\n",
            "s17: 9.979828357696533s\n",
            "s18: 10.588258981704712s\n",
            "s19: 11.125147342681885s\n",
            "s20: 11.572941541671753s\n",
            "s21: 12.041922092437744s\n",
            "s22: 12.527730226516724s\n",
            "s23: 13.075870513916016s\n",
            "s24: 13.704082250595093s\n",
            "s25: 14.239461183547974s\n",
            "s26: 14.9082350730896s\n",
            "s27: 15.456629991531372s\n",
            "s28: 16.136059045791626s\n",
            "s29: 16.67797040939331s\n",
            "s30: 17.26772451400757s\n",
            "s31: 17.97455668449402s\n",
            "s32: 18.634765625s\n",
            "s33: 19.180708646774292s\n",
            "s34: 19.778010845184326s\n",
            "s35: 20.473007202148438s\n",
            "s36: 21.09112811088562s\n",
            "s37: 21.784178495407104s\n",
            "s38: 22.521363258361816s\n",
            "s39: 23.28457283973694s\n",
            "s40: 23.77460503578186s\n",
            "total time for subsampling 11760 recordings: 23.77s\n",
            "rms 150 done\n",
            "\n",
            "\n",
            "RMS Rectification for 200ms window size\n",
            "\n",
            "s01: 1.0688767433166504s\n",
            "s02: 2.5917623043060303s\n",
            "s03: 4.240993022918701s\n",
            "s04: 6.989596128463745s\n",
            "s05: 8.235876321792603s\n",
            "s06: 9.918887376785278s\n",
            "s07: 12.33355450630188s\n",
            "s08: 13.615555763244629s\n",
            "s09: 14.965426921844482s\n",
            "s10: 16.547922611236572s\n",
            "s11: 17.9912006855011s\n",
            "s12: 19.547595739364624s\n",
            "s13: 21.096240758895874s\n",
            "s14: 22.732374668121338s\n",
            "s15: 24.127511262893677s\n",
            "s16: 25.501681089401245s\n",
            "s17: 27.145002603530884s\n",
            "s18: 28.338589668273926s\n",
            "s19: 29.612556219100952s\n",
            "s20: 30.603102922439575s\n",
            "s21: 31.625401973724365s\n",
            "s22: 32.58106589317322s\n",
            "s23: 33.67552089691162s\n",
            "s24: 34.76873159408569s\n",
            "s25: 36.17571973800659s\n",
            "s26: 37.481369495391846s\n",
            "s27: 38.83383011817932s\n",
            "s28: 40.7519314289093s\n",
            "s29: 42.00198030471802s\n",
            "s30: 43.13513493537903s\n",
            "s31: 45.08557987213135s\n",
            "s32: 47.31789469718933s\n",
            "s33: 48.43308472633362s\n",
            "s34: 49.52081608772278s\n",
            "s35: 51.132404804229736s\n",
            "s36: 52.43519997596741s\n",
            "s37: 53.76912021636963s\n",
            "s38: 55.229097843170166s\n",
            "s39: 56.43128490447998s\n",
            "s40: 57.4107232093811s\n",
            "total time for subsampling 11760 recordings: 57.41s\n",
            "rms 200 done\n"
          ]
        }
      ],
      "source": [
        "# @title Create Subsampling\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    new_freq = 100\n",
        "    for rms in [150,200]:\n",
        "        unsampled_data_path = os.path.join(RMS_DATA_PATH_DB2,get_rms_rect_filename(2,rms))\n",
        "        data = np.load(unsampled_data_path)\n",
        "        subsampled_data = {}\n",
        "        print(f\"\\n\\nRMS Rectification for {rms}ms window size\\n\")\n",
        "        t1 = time.time()\n",
        "        for key,emg in data.items():\n",
        "            emg_sub = subsample(emg,2000,new_freq=new_freq)\n",
        "            subsampled_data[key] = emg_sub\n",
        "            if key[3:] == \"g49r06\":\n",
        "              print(f\"{key[:3]}: {time.time() - t1}s\")\n",
        "\n",
        "        total_time = time.time() - t1\n",
        "        print(f\"total time for subsampling {len(data.items())} recordings: {total_time:.2f}s\")\n",
        "\n",
        "        new_path = os.path.join(RMS_DATA_PATH_DB2,get_rms_sub_filename(2,rms,new_freq))\n",
        "        np.savez(new_path,**subsampled_data)\n",
        "\n",
        "        print(f\"rms {rms} done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsUQjviOFHRc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgCB32nHxlLl"
      },
      "source": [
        "# 6 - DATA GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "ZvFh1rPZlOtC"
      },
      "outputs": [],
      "source": [
        "# @title (S,G,R) Combinations for each experiment\n",
        "sgr_domains = {\n",
        "    \"db2\" : {\n",
        "        \"ex1\" : {\n",
        "            \"s_domain\" : {'train' : list(range(1,41)), 'test' : list(range(1,41))},\n",
        "            \"g_domain\" : {'train' : list(range(1,50)), 'test' : list(range(1,50))},\n",
        "            \"r_domain\" : {'train' : [1,3,4,6], 'test' : [2,5]}\n",
        "        },\n",
        "        \"ex2\" : {\n",
        "            \"s_domain\" : {'train' : list(range(1,28)), 'val' : list(range(28,33)),'test' : list(range(33,41))},\n",
        "            \"g_domain\" : {'train' : list(range(1,50)), 'val' : list(range(1,50)), 'test' : list(range(1,50))},\n",
        "            \"r_domain\" : {'train' : list(range(1,7)),  'val' : list(range(1,7)),  'test' : list(range(1,7))}\n",
        "        },\n",
        "        \"ex3\" : {\n",
        "            \"s_domain\" : {'train' : list(range(1,41)), 'val' : list(range(1,41)), 'test' : list(range(1,41))},\n",
        "            \"g_domain\" : {'train' : list(range(1,35)), 'val' : list(range(35,41)),'test' : list(range(41,50))},\n",
        "            \"r_domain\" : {'train' : list(range(1,7)),  'val' : list(range(1,7)),  'test' : list(range(1,7))}\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"db5\" : {\n",
        "\n",
        "    },\n",
        "\n",
        "    \"db1\" : {\n",
        "\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b3IewhCPjqHH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Class Task Generator\n",
        "\n",
        "class FileInfoProvider:\n",
        "    def __init__(self, db, rms, N, k, ex, mode,get_subsampled_data:bool=False):\n",
        "        if db == 2:\n",
        "            self.data_directory = RMS_DATA_PATH_DB2\n",
        "            if get_subsampled_data == True:\n",
        "                self.data_filepath = os.path.join(self.data_directory, get_rms_sub_filename(db, rms,100))\n",
        "            else:\n",
        "                self.data_filepath = os.path.join(self.data_directory, get_rms_rect_filename(db, rms))\n",
        "\n",
        "        elif db == 1:\n",
        "            self.data_directory = PROCESSED_DATA_PATH_DB1\n",
        "            self.data_filepath = os.path.join(self.data_directory,'db1_raw.npz')\n",
        "        elif db == 5:\n",
        "            self.data_directory = PROCESSED_DATA_PATH_DB5\n",
        "            self.data_filepath = os.path.join(self.data_directory,'db5_raw.npz')\n",
        "\n",
        "        self.N = N\n",
        "        self.k = k\n",
        "        self.ex = ex\n",
        "        self.mode = mode\n",
        "\n",
        "    def setMode(self,mode):\n",
        "        self.mode = mode\n",
        "        return\n",
        "\n",
        "    def getDataDirectoryPath(self):\n",
        "        return self.data_directory\n",
        "\n",
        "    def getDataFullPath(self):\n",
        "        return self.data_filepath\n",
        "\n",
        "    def getTasksFileFullPath(self):\n",
        "        return os.path.join(TASKS_FILE_PATH_DB2,get_tasks_filename(ex=self.ex, N=self.N, k=self.k, mode=self.mode))\n",
        "\n",
        "\n",
        "class TaskGenerator(utils.Sequence):\n",
        "    def __init__(self, network_type:str, experiment:str, way:int, shot:int, mode:str,data_intake:str, database:int ,  preprocessing_config:dict,aug_enabled:bool, aug_config:dict, batch_size:int=1, batches: int = 1000, rms_win_size:int=200):\n",
        "        self.experiment = experiment\n",
        "        self.way = way\n",
        "        self.shot = shot\n",
        "        self.mode = mode\n",
        "        self.data_intake = ''\n",
        "        self.network_type = network_type\n",
        "        self.task_generator = None\n",
        "        self.db = database\n",
        "\n",
        "        # Preprocessing and augmentation configurations\n",
        "        self.preproc_config = preprocessing_config\n",
        "        self.window_size = self.getWindowSize()\n",
        "        self.rms_win_size = rms_win_size\n",
        "        self.fileInfoProvider = FileInfoProvider(self.db, self.rms_win_size, N = self.way, k = self.shot, ex = self.experiment, mode=self.mode, get_subsampled_data=True)\n",
        "        self.aug_enabled = aug_enabled\n",
        "        if self.aug_enabled == True:\n",
        "            self.aug_config = aug_config\n",
        "            self.data_aug = {}\n",
        "\n",
        "        # Only used if data_intake == 'csv'\n",
        "        self.support_keys = []\n",
        "        self.support_seg_start = []\n",
        "        self.query_keys = []\n",
        "        self.query_seg_start = []\n",
        "        self.query_gest_indices = []\n",
        "\n",
        "        # S,G,R Domains and acceptable keys\n",
        "        self.s_domain = []\n",
        "        self.g_domain = []\n",
        "        self.r_domain = []\n",
        "        self.s_r_pairs = []\n",
        "        self.get_sgr_domains()\n",
        "        self.key_list = self.get_all_acceptable_keys()\n",
        "\n",
        "        print(f\"~~~ {self.mode} loader ~~~\".upper())\n",
        "        self.get__data()\n",
        "        # self.keyAppDict = self.get_key_app_dict()\n",
        "        self.channels = self.getNumberOfChannels()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.batches_per_epoch = batches\n",
        "\n",
        "        # No need for any other data intake type other than 'generate'\n",
        "        self.set_data_intake_type('generate')\n",
        "\n",
        "        return\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.network_type == \"protoNet\":\n",
        "            all_keys = self.task_generator(index)\n",
        "            support_batch, query_batch, labels_batch = self.get_task_data_based_on_keys(*all_keys)\n",
        "        elif self.network_type == \"siamNet\":\n",
        "            support_batch, query_batch, labels_batch = self.task_generator(index)\n",
        "\n",
        "        return [support_batch, query_batch], labels_batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.batches_per_epoch\n",
        "\n",
        "    def get__data(self):\n",
        "        \"\"\" As of now, apply_preprocessing is only used here. Therefore, total number of subjects and final\n",
        "            subject key sub-fix are manually computed here as well \"\"\"\n",
        "        last_rep = self.r_domain[-1]\n",
        "        last_gest = self.g_domain[-1]\n",
        "        last_subfix = getKey(s=1,g=last_gest, r=last_rep)[3:]\n",
        "\n",
        "        self.data, self.segments = apply_preprocessing(\n",
        "            data_path=self.fileInfoProvider.getDataFullPath(),\n",
        "            key_list=self.key_list, final_sample_subfix=last_subfix,\n",
        "            total_subjects=len(self.s_domain),\n",
        "            config_dict=self.preproc_config\n",
        "        )\n",
        "        if self.aug_enabled:\n",
        "            self.data_aug = apply_augmentation(data=self.data, config_dict=self.aug_config, total_subjects=len(self.s_domain),final_sample_subfix=last_subfix)\n",
        "        print()\n",
        "\n",
        "        return\n",
        "\n",
        "    def load_tasks_from_file(self):\n",
        "        full_path = self.fileInfoProvider.getTasksFileFullPath()\n",
        "        print('Loading tasks...')\n",
        "\n",
        "        df = pd.read_csv(full_path)\n",
        "        s_keys = df.iloc[:,:-3:2]\n",
        "        s_seg = df.iloc[:,1:-3:2]\n",
        "        q_keys = df.iloc[:,-3]\n",
        "        q_seg = df.iloc[:,-2]\n",
        "        q_label = df.iloc[:,-1]\n",
        "\n",
        "        self.support_keys = np.reshape(s_keys.to_numpy(),[len(s_seg),self.way,self.shot])\n",
        "        self.support_seg_start = np.reshape(s_seg.to_numpy(dtype=np.int32),[len(s_seg),self.way,self.shot])\n",
        "\n",
        "        self.query_keys = q_keys.to_numpy()\n",
        "        self.query_seg_start = q_seg.to_numpy()\n",
        "\n",
        "        self.query_gest_indices = q_label.to_numpy()\n",
        "\n",
        "        print(\"\\n...tasks have been loaded.\")\n",
        "\n",
        "    def reshape_support_set(self,support_flattened):\n",
        "        support_set = []\n",
        "        for i in range(self.way):\n",
        "            support_set.append(support_flattened[i*self.shot:(i+1)*self.shot])\n",
        "\n",
        "        return support_set\n",
        "\n",
        "    # Used for creating a dictionary keeping track of the number of times each key has been used\n",
        "    # Used only for checking whether the task sampling process is correct\n",
        "    def get_key_app_dict(self):\n",
        "        keyAppDict = {}\n",
        "        for key in self.data.keys():\n",
        "            if self.aug_enabled:\n",
        "                keyAppDict[key] = [0,0]\n",
        "            else:\n",
        "                keyAppDict[key] = [0]\n",
        "        return keyAppDict\n",
        "\n",
        "\n",
        "    def getNumberOfChannels(self):\n",
        "        random_key = random.choice(list(self.data.keys()))\n",
        "        random_sample = self.data[random_key]\n",
        "        return random_sample.shape[1]\n",
        "\n",
        "    # Returns the window size in number of time samples\n",
        "    # i.e. if the sampling rate is 100Hz and the window size is meant to be 150ms that would return 15 samples\n",
        "    def getWindowSize(self):\n",
        "        w_ms = self.preproc_config['params']['SEGMENT']['window_size_ms']\n",
        "        fs = self.preproc_config['params']['SEGMENT']['fs']\n",
        "        return int((w_ms * fs) / 1000)\n",
        "\n",
        "    def getKeys(self,*entries) -> list:\n",
        "        return [getKey(s,g,r) for s,r,g in entries]\n",
        "\n",
        "    def getKeys_in_order(self,*entries) -> list:\n",
        "        return [getKey(s,g,r) for s,g,r in entries]\n",
        "\n",
        "    def set_s_r_pairs(self) -> list:\n",
        "        self.s_r_pairs = [(s,r) for s in self.s_domain for r in self.r_domain]\n",
        "\n",
        "    \"\"\"\n",
        "    DESCRIPTION\n",
        "        Depending on the experiment and the database used there are different values for the s,g,r fields\n",
        "        These are all taken from the dictionary containing the configurations\n",
        "    \"\"\"\n",
        "    def get_sgr_domains(self):\n",
        "        exp_key = f'ex{self.experiment[0]}'\n",
        "        db_key = f'db{self.db}'\n",
        "        self.s_domain = sgr_domains[db_key][exp_key][\"s_domain\"][self.mode]\n",
        "        self.g_domain = sgr_domains[db_key][exp_key][\"g_domain\"][self.mode]\n",
        "        self.r_domain = sgr_domains[db_key][exp_key][\"r_domain\"][self.mode]\n",
        "        self.set_s_r_pairs()\n",
        "\n",
        "        return\n",
        "\n",
        "    \"\"\"\n",
        "    DESCRIPTION\n",
        "        Returns a list of all possible acceptable key combinations depending on the s,g,r domains\n",
        "\n",
        "    \"\"\"\n",
        "    def get_all_acceptable_keys(self):\n",
        "        sgr_comb_list = [(s,g,r) for s in self.s_domain for g in self.g_domain for r in self.r_domain]\n",
        "        return self.getKeys_in_order(*sgr_comb_list)\n",
        "\n",
        "    def plotKeyAppHist(self):\n",
        "        plotDictBar(self.keyAppDict)\n",
        "\n",
        "\n",
        "    def get_segment_of_semg(self, key, segment_start):\n",
        "        # segment_start = random.choice(self.segments[key])\n",
        "        indices = np.arange(segment_start, segment_start+self.window_size)\n",
        "        if not self.aug_enabled:\n",
        "            x = np.take(self.data[key],indices,axis=0)\n",
        "            # self.keyAppDict[key][0] += 1\n",
        "        else:\n",
        "            #TODO - Might be more depending on the number of unique augmentation techniques used\n",
        "            ind = np.random.choice([0,1]) # 0: non-aug, 1: aug\n",
        "            x = np.take([self.data[key], self.data_aug[key]][ind],indices,axis=0)\n",
        "            # self.keyAppDict[key][ind] += 1\n",
        "\n",
        "        return x\n",
        "\n",
        "    def set_batch_size(self, batch_size:int):\n",
        "        self.batch_size = batch_size\n",
        "        return\n",
        "\n",
        "    \"\"\"\n",
        "        PARAMETERS\n",
        "        data\n",
        "    \"\"\"\n",
        "    def set_data_intake_type(self,data_intake):\n",
        "        if self.data_intake == data_intake or data_intake not in ['csv','generate']:\n",
        "            return\n",
        "        self.data_intake = data_intake\n",
        "\n",
        "        if self.network_type == \"protoNet\":\n",
        "            if self.data_intake == \"csv\":\n",
        "                self.load_tasks_from_file()\n",
        "                self.task_generator = self.get_premade_keys\n",
        "            elif self.data_intake == \"generate\":\n",
        "                if self.experiment == '2a':\n",
        "                    self.task_generator = self.generate_task_keys_2a\n",
        "                elif self.experiment in ['1','2b','3']:\n",
        "                    self.task_generator = self.generate_task_keys\n",
        "        elif self.network_type == \"siamNet\":\n",
        "            self.task_generator = self.generate_siamNet_task\n",
        "        else:\n",
        "            exit(\"invalid network type in TaskGenerator __init__. Should be between 'siamNet' and 'protoNet'\")\n",
        "\n",
        "        return\n",
        "\n",
        "    def getMode(self):\n",
        "        return self.mode\n",
        "    def setMode(self,mode):\n",
        "        if self.mode == mode:\n",
        "            return\n",
        "        self.mode = mode\n",
        "        self.fileInfoProvider.setMode(self.mode)\n",
        "        # self.s_r_pairs gets taken care of by self.get_sgr_domains\n",
        "        self.get_sgr_domains()\n",
        "\n",
        "        # In case tasks are premade and loaded from a csv file, they need to be reloaded since each csv file\n",
        "        # depends on the mode and thus a different file contains the tak keys for that different mode\n",
        "        if self.data_intake == \"csv\":\n",
        "            # t1 = time.time()\n",
        "            self.load_tasks_from_file()\n",
        "\n",
        "        return\n",
        "\n",
        "    def set_iterations_per_epoch(self,iterations):\n",
        "        self.batches_per_epoch = iterations\n",
        "        return\n",
        "\n",
        "    def set_aug_enabled(self,aug_enabled):\n",
        "        self.aug_enabled = aug_enabled\n",
        "\n",
        "\n",
        "    def generate_task_keys(self, index):\n",
        "        support_set_keys = []\n",
        "        query_keys = []\n",
        "        query_gest_indices = []\n",
        "        support_segments_starting_indices = []\n",
        "        query_segments_starting_indices = []\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            support_set = []\n",
        "            start_indices = []\n",
        "\n",
        "            # Select N random gestures\n",
        "            task_gestures = random.sample(self.g_domain, self.way)\n",
        "            # Select 1 out of the N to be the query one and keep it index (which of the 5 it is)\n",
        "            query_gesture_index, chosen_query_gest = random.choice(list(enumerate(task_gestures)))\n",
        "            shot_list = [self.shot]*self.way\n",
        "            shot_list[query_gesture_index] += 1\n",
        "\n",
        "            support_pairs = [random.sample(self.s_r_pairs, shot_number) for shot_number in shot_list]\n",
        "            for i,g in enumerate(task_gestures):\n",
        "                sgr_list = [pair + (g,) for pair in support_pairs[i]]\n",
        "                category_keys = self.getKeys(*sgr_list)\n",
        "                support_set.append(category_keys)\n",
        "                start_indices.append([random.choice(self.segments[key]) for key in category_keys])\n",
        "\n",
        "            query_key = support_set[query_gesture_index].pop()\n",
        "            query_seg_start_index = start_indices[query_gesture_index].pop()\n",
        "\n",
        "            support_set_keys.append(support_set)\n",
        "            support_segments_starting_indices.append(start_indices)\n",
        "            query_keys.append(query_key)\n",
        "            query_segments_starting_indices.append(query_seg_start_index)\n",
        "            query_gest_indices.append(query_gesture_index)\n",
        "\n",
        "        return support_set_keys, support_segments_starting_indices, query_keys, query_segments_starting_indices, query_gest_indices\n",
        "\n",
        "    def generate_task_keys_2a(self, index):\n",
        "        support_set_keys = []\n",
        "        query_keys = []\n",
        "        query_gest_indices = []\n",
        "        support_segments_starting_indices = []\n",
        "        query_segments_starting_indices = []\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            support_set = []\n",
        "            start_indices = []\n",
        "\n",
        "            task_gestures = random.sample(self.g_domain, self.way)\n",
        "            query_gesture_index, chosen_query_gest = random.choice(list(enumerate(task_gestures)))\n",
        "            chosen_subject = random.choice(self.s_domain)\n",
        "            shot_list = [self.shot] * self.way\n",
        "            shot_list[query_gesture_index] += 1\n",
        "\n",
        "            # Since each of the N gestures is taken from the same subject, the only variant in the (s,g,r)\n",
        "            # combination of each key is the 'r'\n",
        "            reps = [random.sample(self.r_domain, shot_number) for shot_number in shot_list]\n",
        "            for i,g in enumerate(task_gestures):\n",
        "                sgr_list = [(chosen_subject,rep,g) for rep in reps[i]]\n",
        "                category_keys = self.getKeys(*sgr_list)\n",
        "                support_set.append(category_keys)\n",
        "                start_indices.append([random.choice(self.segments[key]) for key in category_keys])\n",
        "\n",
        "            query_key = support_set[query_gesture_index].pop()\n",
        "            query_seg_start_index = start_indices[query_gesture_index].pop()\n",
        "\n",
        "            support_set_keys.append(support_set)\n",
        "            support_segments_starting_indices.append(start_indices)\n",
        "            query_keys.append(query_key)\n",
        "            query_segments_starting_indices.append(query_seg_start_index)\n",
        "            query_gest_indices.append(query_gesture_index)\n",
        "\n",
        "        return support_set_keys, support_segments_starting_indices, query_keys, query_segments_starting_indices, query_gest_indices\n",
        "\n",
        "    \"\"\"\n",
        "        Unlike generate_task_keys and generate_task_keys_2a it returns the data instead of their keys\n",
        "    \"\"\"\n",
        "    def generate_siamNet_task(self, index):\n",
        "        x1_batch = []\n",
        "        x2_batch = []\n",
        "        labels_batch = []\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            # 0 for pair of different classes and 1 for pair of same class\n",
        "            label = random.choice([0,1])\n",
        "            if label == 0:\n",
        "                gests = random.sample(self.g_domain, 2)\n",
        "                sgr_list = [random.choice(self.s_r_pairs) + (g,) for g in gests]\n",
        "\n",
        "            else:\n",
        "                gest = random.choice(self.g_domain)\n",
        "                s_r_pairs = random.sample(self.s_r_pairs,2)\n",
        "                sgr_list = [s_r_pair + (gest,) for s_r_pair in s_r_pairs]\n",
        "\n",
        "            key1,key2 = self.getKeys(*sgr_list)\n",
        "\n",
        "            x1_batch.append(self.get_segment_of_semg(key1, random.choice(self.segments[key1])))\n",
        "            x2_batch.append(self.get_segment_of_semg(key2, random.choice(self.segments[key2])))\n",
        "            labels_batch.append(label)\n",
        "\n",
        "        return np.array(x1_batch), np.array(x2_batch), np.array(labels_batch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_premade_keys(self,index):\n",
        "        ind = np.arange(index*self.batch_size, (index+1)*self.batch_size)\n",
        "        support_keys = self.support_keys[ind]\n",
        "        query_keys = self.query_keys[ind]\n",
        "        support_seg = self.support_seg_start[ind]\n",
        "        query_seg = self.query_seg_start[ind]\n",
        "        gest_ind = self.query_gest_indices[ind]\n",
        "\n",
        "        return support_keys, support_seg, query_keys, query_seg, gest_ind\n",
        "\n",
        "    def get_task_data_based_on_keys(self, support_keys, support_seg_starting_indices, query_keys, query_seg_starting_indices, query_gesture_indices):\n",
        "        support_set_batch = []\n",
        "        query_batch = []\n",
        "        labels_batch = []\n",
        "\n",
        "        # Each list should have length == self.batch_size\n",
        "        for i in range(len(support_keys)):\n",
        "\n",
        "            support_set = np.empty((self.way, self.shot, self.window_size, self.channels, 1))\n",
        "            query_image = np.empty((1, self.channels, self.window_size, 1))\n",
        "\n",
        "            for j, gest_key_list in enumerate(support_keys[i]):\n",
        "                shots = [self.get_segment_of_semg(key,support_seg_starting_indices[i][j][k]) for k,key in enumerate(gest_key_list)]\n",
        "                support_set[j] = np.array(shots)\n",
        "\n",
        "            query_image = np.expand_dims(self.get_segment_of_semg(query_keys[i],query_seg_starting_indices[i]), axis=0)\n",
        "            label = utils.to_categorical([query_gesture_indices[i]], num_classes=self.way)\n",
        "\n",
        "            support_set_batch.append(support_set)\n",
        "            query_batch.append(query_image)\n",
        "            labels_batch.append(label[0])\n",
        "\n",
        "        return np.array(support_set_batch), np.array(query_batch), np.array(labels_batch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P0xNuqXexrh"
      },
      "source": [
        "# 7 - GENERATE TASKS AND CONFIG FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GaBMDn02yxiE"
      },
      "outputs": [],
      "source": [
        "# @title Generate tasks\n",
        "\n",
        "def create_csv_lines(support_keys,support_seg_start,query_keys,query_seg_start,query_gest_ind):\n",
        "    batch_size,way,shot = np.array(support_keys).shape\n",
        "    task_lines = np.empty([batch_size,2*(way*shot+1)+1],dtype='U9')\n",
        "    s_keys_np = np.reshape(np.array(support_keys),[batch_size,way*shot])\n",
        "    q_keys_np = np.expand_dims(np.array(query_keys),-1)\n",
        "    s_q_keys = np.concatenate((s_keys_np,q_keys_np),axis=1)\n",
        "    s_seg_np = np.reshape(np.array(support_seg_start),[batch_size,way*shot])\n",
        "    q_seg_np = np.expand_dims(np.array(query_seg_start),-1)\n",
        "    s_q_seg = np.concatenate((s_seg_np,q_seg_np),axis=1)\n",
        "\n",
        "    task_lines[:,:-1:2] = s_q_keys\n",
        "    task_lines[:,1:-1:2] = s_q_seg\n",
        "    task_lines[:,-1] = query_gest_ind\n",
        "\n",
        "    return task_lines\n",
        "\n",
        "def save_tasks(task_lines,db,experiment,way,shot,mode):\n",
        "    if db == 2:\n",
        "      dirpath = TASKS_FILE_PATH_DB2\n",
        "    elif db == 1:\n",
        "      dirpath = TASKS_FILE_PATH_DB1\n",
        "    elif db == 5:\n",
        "      dirpath = TASKS_FILE_PATH_DB5\n",
        "\n",
        "    full_path = os.path.join(dirpath,get_tasks_filename(ex=experiment,N=way,k=shot,mode=mode))\n",
        "\n",
        "    with open(full_path,'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        for task in task_lines:\n",
        "            writer.writerow(task)\n",
        "    print(f\"Saved at: '{full_path}'\")\n",
        "\n",
        "way = 5\n",
        "shot = 5\n",
        "ex = '1'\n",
        "db = 2\n",
        "\n",
        "num_batches = 10000\n",
        "batch_size = 64\n",
        "\n",
        "mode = 'train'\n",
        "preproc_config = get_config_from_json_file(mode = 'preproc', filename = 'db2_no_lpf')\n",
        "Gen = TaskGenerator(experiment='1', network_type='protoNet', way=way, shot=shot, mode=mode, data_intake='generate',database=db, preprocessing_config=preproc_config, aug_enabled=False, aug_config=None, rms_win_size=200, batch_size=batch_size, batches=num_batches, print_labels=False, print_labels_frequency=0)\n",
        "\n",
        "t1 = time.time()\n",
        "task_lines = np.empty([1+num_batches*batch_size,2*(way*shot+1)+1],dtype='U9')\n",
        "headers = [el for i in range(way) for j in range(shot) for el in (f\"c{i+1}_e{j+1}_key\", f\"c{i+1}_e{j+1}_seg\")] + ['query_key','query_seg','label']\n",
        "task_lines[0] = headers\n",
        "\n",
        "print(\"Preparing tasks...\")\n",
        "for i in range(num_batches):\n",
        "    keys = Gen.generate_task_keys(i)\n",
        "    task_line =  create_csv_lines(*keys)\n",
        "    task_lines[1 + i*batch_size : 1 + (i+1)*batch_size] = task_line\n",
        "    if i%100 == 0:\n",
        "        print(f\"Batch {i}/{num_batches} : {time.time()-t1:.2f}\")\n",
        "\n",
        "print(f\"Batch {i+1}/{num_batches} : {time.time() - t1:.2f}\")\n",
        "\n",
        "print(\"\\n...tasks have been prepared\")\n",
        "print(f\"total time for {num_batches*batch_size} ({way}way - {shot}shot) tasks: {time.time()-t1:.2f}\")\n",
        "save_tasks(task_lines,db=db, experiment=ex, way=way, shot=shot, mode=mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wmyqowtbTaRW"
      },
      "outputs": [],
      "source": [
        "# @title Add Config\n",
        "\n",
        "preprocess_config = {\n",
        "    \"SUBSAMPLE\" :   {\"enable\" : False,\n",
        "                     \"params\" : {\"init_freq\" : 2000, \"new_freq\" : 100}},\n",
        "\n",
        "    \"DISCARD\"   :   {\"enable\" : True ,\n",
        "                     \"params\" : {\"seconds_to_keep\" : 5.0, \"fs\" : 100}},\n",
        "\n",
        "    \"LOWPASS\"   :   {\"enable\" : True,\n",
        "                     \"params\" : {\"fc\": 1, \"fs\": 100, \"N\": 1}},\n",
        "\n",
        "    \"MIN-MAX\"   :   {\"enable\" : True,\n",
        "                     \"params\" : {}},\n",
        "\n",
        "    \"M-LAW\"     :   {\"enable\" : False,\n",
        "                     \"params\" : {\"mu\":2048, \"scaling_type\":\"all\"}},\n",
        "\n",
        "    \"SEGMENT\"   :   {\"enable\" : True ,\n",
        "                     \"params\" : {\"window_size_ms\" : 150, \"window_step_ms\" : 60, \"fs\" : 100}}\n",
        "}\n",
        "\n",
        "preprocess_ops = {key : preprocess_config[key][\"enable\"] for key in preprocess_config.keys()}\n",
        "preprocess_params = {key : preprocess_config[key][\"params\"] for key in preprocess_config.keys()}\n",
        "\n",
        "\n",
        "\n",
        "# AUGMENTATION\n",
        "augmentation_config = {\n",
        "    \"AWGN\" : {\"enable\" : True ,\n",
        "              \"params\" : {\"snr_db\" : 25}},\n",
        "\n",
        "    \"FLIP\" : {\"enable\" : False ,\n",
        "              \"params\" : None}\n",
        "}\n",
        "\n",
        "augmentation_ops = {key : augmentation_config[key][\"enable\"] for key in augmentation_config.keys()}\n",
        "augmentation_params = {key : augmentation_config[key][\"params\"] for key in augmentation_config.keys()}\n",
        "\n",
        "preproc_config_dict = {\"ops\" : preprocess_ops, \"params\" : preprocess_params}\n",
        "aug_config_dict = {\"ops\": augmentation_ops, \"params\": augmentation_params}\n",
        "\n",
        "def save_config(mode:str, filename:str):\n",
        "    if mode == \"preproc\" :\n",
        "        config_dict = {\"ops\" : preprocess_ops, \"params\" : preprocess_params}\n",
        "        full_filename = get_config_full_filename(mode='preproc', name=filename)\n",
        "        path = os.path.join(DATA_CONFIG_PATH_PREPROC, full_filename)\n",
        "\n",
        "    elif mode == \"aug\" :\n",
        "        config_dict = {\"ops\": augmentation_ops, \"params\": augmentation_params}\n",
        "        full_filename = get_config_full_filename(mode='aug', name=filename)\n",
        "        path = os.path.join(DATA_CONFIG_PATH_AUG,full_filename)\n",
        "\n",
        "    elif mode == \"train\" :\n",
        "        return\n",
        "\n",
        "    with open(path, 'w') as file:\n",
        "        json.dump(config_dict, file, indent=4)\n",
        "#mode = 'aug'\n",
        "#name = 'db2_awgn_snr25'\n",
        "mode = 'preproc'\n",
        "name = 'db2_discard_5.0_lpf_minmax_no_muLaw'\n",
        "save_config(mode, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx2uHVCK3IMF"
      },
      "source": [
        "# 8 - TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "fM6UHxgYsW2R"
      },
      "outputs": [],
      "source": [
        "# @title Custom callbacks\n",
        "\n",
        "class IterationLoggingCallback(keras.callbacks.Callback):\n",
        "    # def on_batch_end(self, batch, logs=None):\n",
        "    #     if (batch % 100) == 0:\n",
        "    #         # print(f\"Batch {batch + 1}: loss = {logs.get('loss'):.2f}\\n\")\n",
        "    #         print()\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        super().on_epoch_end(epoch, logs)\n",
        "\n",
        "class TrainingInfoCallback(keras.callbacks.Callback):\n",
        "    # TODO - take into account changes regarding best_val_loss etc\n",
        "    def __init__(self, file_path, model,  batch_size, model_filename, model_backbone_name, experiment, iterations_per_epoch, validation_steps, preprocessing_dict, aug_enabled, aug_dict, data_intake, rms, db):\n",
        "        super(TrainingInfoCallback, self).__init__()\n",
        "        self.file_path = file_path\n",
        "        self.model = model\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # 'model_protoNet_1.h5' -> 'model_protoNet_1'\n",
        "        model_filename = model_filename.split('.')[0]\n",
        "        self.json_filename = model_filename + \"_training_info.json\"\n",
        "        self.txt_res_filename = model_filename + \"_results.txt\"\n",
        "        self.json_fullpath = os.path.join(self.file_path, self.json_filename)\n",
        "        self.txt_res_fullpath = os.path.join(self.file_path, self.txt_res_filename)\n",
        "\n",
        "        self.model_backbone_name = model_backbone_name\n",
        "        self.experiment = experiment\n",
        "        self.iterations_per_epoch = iterations_per_epoch\n",
        "        self.validation_steps = validation_steps\n",
        "        self.preprocessing_dict = preprocessing_dict\n",
        "        self.aug_enabled = aug_enabled\n",
        "        self.aug_dict = aug_dict\n",
        "\n",
        "\n",
        "        self.best_epoch_val_loss = 0\n",
        "        self.best_epoch_val_acc = 0\n",
        "\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.best_val_acc = 0.0\n",
        "\n",
        "        self.best_loss_lr = self.get_lr()\n",
        "        self.best_acc_lr = self.get_lr()\n",
        "\n",
        "        self.load_results_if_exist()\n",
        "\n",
        "        self.data_intake = data_intake\n",
        "        self.rms         = rms\n",
        "        self.db          = db\n",
        "\n",
        "    def load_results_if_exist(self):\n",
        "        if os.path.exists(self.json_fullpath):\n",
        "            if os.path.exists(self.json_fullpath):\n",
        "                with open(self.json_fullpath, 'r') as f:\n",
        "                    training_info = json.load(f)\n",
        "\n",
        "            self.best_epoch_val_loss = training_info[\"RESULTS\"][\"BEST_EPOCH_LOSS\"]\n",
        "            self.best_epoch_val_acc = training_info[\"RESULTS\"][\"BEST_EPOCH_ACC\"]\n",
        "            self.best_val_loss = training_info[\"RESULTS\"][\"BEST_VAL_LOSS\"]\n",
        "            self.best_val_acc = training_info[\"RESULTS\"][\"BEST_VAL_ACC\"]\n",
        "            self.best_loss_lr = training_info[\"RESULTS\"][\"BEST_EPOCH_LOSS_LEARNING_RATE\"]\n",
        "            self.best_acc_lr = training_info[\"RESULTS\"][\"BEST_EPOCH_ACC_LEARNING_RATE\"]\n",
        "\n",
        "\n",
        "    def round_results(self,logs):\n",
        "        return {key: round(value, 4) for key, value in logs.items()}\n",
        "\n",
        "    def get_lr(self):\n",
        "        return float(self.model.optimizer.learning_rate.numpy())\n",
        "    def update_json_log_file(self,epoch):\n",
        "        if os.path.exists(self.json_fullpath):\n",
        "            with open(self.json_fullpath, 'r') as f:\n",
        "                training_info = json.load(f)\n",
        "            # training_info[\"RESULTS\"][f\"epoch {epoch+1}\"] = self.round_results(logs)\n",
        "            training_info[\"RESULTS\"][\"TOTAL_EPOCHS\"] = epoch+1\n",
        "            training_info[\"RESULTS\"][\"LATEST_EPOCH_LEARNING_RATE\"] = self.get_lr()\n",
        "\n",
        "            training_info[\"RESULTS\"][\"BEST_VAL_LOSS\"] = self.best_val_loss\n",
        "            training_info[\"RESULTS\"][\"BEST_EPOCH_LOSS\"] = self.best_epoch_val_loss\n",
        "            training_info[\"RESULTS\"][\"BEST_EPOCH_LOSS_LEARNING_RATE\"] = self.best_loss_lr\n",
        "\n",
        "            training_info[\"RESULTS\"][\"BEST_VAL_ACC\"] = self.best_val_acc\n",
        "            training_info[\"RESULTS\"][\"BEST_EPOCH_ACC\"] = self.best_epoch_val_acc\n",
        "            training_info[\"RESULTS\"][\"BEST_EPOCH_ACC_LEARNING_RATE\"] = self.best_acc_lr\n",
        "\n",
        "        else:\n",
        "            # Create a dictionary with training info\n",
        "            training_info = {\n",
        "                \"MODEL\" : {\n",
        "                    \"NAME\" : self.model.name,\n",
        "                    \"BASE\" : self.model_backbone_name\n",
        "                },\n",
        "                \"PROCESSING\" : {\n",
        "                    \"PREPROCESSING\" : self.preprocessing_dict,\n",
        "                    \"AUG_ENABLED\"   : self.aug_enabled,\n",
        "                    \"AUGMENTATION\"  : self.aug_dict\n",
        "                },\n",
        "                \"TRAINING_INFO\" : {\n",
        "                    \"EXPERIMENT\" : self.experiment,\n",
        "                    \"BATCH_SIZE\" : self.batch_size,\n",
        "                    \"ITERATIONS_PER_EPOCH\" : self.iterations_per_epoch,\n",
        "                    \"VALIDATION_STEPS\" : self.validation_steps,\n",
        "                    \"OPTIMIZER\" : self.model.optimizer._name,\n",
        "                    \"LOSS\" : self.model.loss,\n",
        "                    \"METRICS\" : self.model.metrics_names,\n",
        "                },\n",
        "                \"RESULTS\": {\n",
        "                    \"TOTAL_EPOCHS\": epoch + 1,\n",
        "                    \"BEST_VAL_LOSS\": self.best_val_loss,\n",
        "                    \"BEST_VAL_ACC\": self.best_val_acc,\n",
        "                    \"BEST_EPOCH_LOSS\": self.best_epoch_val_loss,\n",
        "                    \"BEST_EPOCH_ACC\": self.best_epoch_val_acc,\n",
        "                    \"LATEST_EPOCH_LEARNING_RATE\": self.get_lr(),\n",
        "                    \"BEST_EPOCH_LOSS_LEARNING_RATE\": self.best_loss_lr,\n",
        "                    \"BEST_EPOCH_ACC_LEARNING_RATE\": self.best_acc_lr\n",
        "                },\n",
        "                \"DATA_GENERATOR\" : {\n",
        "                    \"DATA_INTAKE\" : self.data_intake,\n",
        "                    \"RMS\" : self.rms,\n",
        "                    \"DB\" : self.db\n",
        "                }\n",
        "            }\n",
        "        # Save the dictionary as a JSON file\n",
        "        with open(os.path.join(self.file_path,self.json_filename), 'w') as file:\n",
        "            json.dump(training_info, file, indent=4)\n",
        "\n",
        "    def write_txt_res_line(self,epoch,logs):\n",
        "        train_acc = logs['train_accuracy']\n",
        "        train_loss = logs['train_loss']\n",
        "        val_acc = logs['val_accuracy']\n",
        "        val_loss = logs['val_loss']\n",
        "\n",
        "        # Format the result line\n",
        "        result_line = f\"{epoch + 1:<5}\\t{train_acc:<15.4f}\\t{train_loss:<15.4f}\\t{val_acc:<15.4f}\\t{val_loss:<15.4f}\\n\"\n",
        "\n",
        "        # Append the result line to the file\n",
        "        with open(self.txt_res_fullpath, 'a') as f:\n",
        "            f.write(result_line)\n",
        "    def update_txt_results_file(self,epoch,logs=None):\n",
        "        if not os.path.exists(self.txt_res_fullpath):\n",
        "            with open(self.txt_res_fullpath,'w') as res_file:\n",
        "                column_names = f\"{'Epoch':<5}\\t{'Train Accuracy':<15}\\t{'Train Loss':<15}\\t{'Val Accuracy':<15}\\t{'Val Loss':<15}\\n\"\n",
        "                res_file.write(column_names)\n",
        "                res_file.write(\"-\" * 65 + \"\\n\")\n",
        "\n",
        "        self.write_txt_res_line(epoch,logs)\n",
        "\n",
        "    # logs has the following form: {'train_loss':1.2, 'train_accuracy':0.6, 'val_loss':1.4, 'val_accuracy':0.5}\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.update_json_log_file(epoch)\n",
        "        self.update_txt_results_file(epoch,logs)\n",
        "\n",
        "        return\n",
        "\n",
        "class ReduceLrOnPlateauCustom(keras.callbacks.Callback):\n",
        "    def __init__(self, model, reduction_factor, min_delta, best_val_loss , best_val_accuracy, patience, cooldown_patience, criterion=\"loss\", epochs_without_improvement=0, cooldown_counter=0, min_lr=1e-5):\n",
        "        super(ReduceLrOnPlateauCustom,self).__init__()\n",
        "\n",
        "        # Model and values\n",
        "        self.model = model\n",
        "        self.min_delta = min_delta\n",
        "        self.best_val_loss = best_val_loss\n",
        "        self.best_val_accuracy = best_val_accuracy\n",
        "\n",
        "        self.min_lr = min_lr\n",
        "        self.reduction_factor = reduction_factor\n",
        "\n",
        "        # Lr reduction patience\n",
        "        self.patience = patience\n",
        "        self.epochs_without_improvement = epochs_without_improvement\n",
        "\n",
        "        # Cooldown patience\n",
        "        self.cooldown_patience = cooldown_patience\n",
        "        self.cooldown_counter = cooldown_counter\n",
        "\n",
        "        # Criterion\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_lr = float(self.model.optimizer.learning_rate.numpy())\n",
        "        val_loss = logs['val_loss']\n",
        "        val_accuracy = logs['val_accuracy']\n",
        "        min_lr_reached = (current_lr <= self.min_lr)\n",
        "        if min_lr_reached == True:\n",
        "            return True\n",
        "        improvement_made = False\n",
        "\n",
        "        # Improvement\n",
        "        if self.criterion == \"loss\":\n",
        "            if val_loss < self.best_val_loss - self.min_delta:\n",
        "                print(f\"new best loss {val_loss:.4f}\")\n",
        "                self.best_val_loss = val_loss\n",
        "                self.epochs_without_improvement = 0\n",
        "                improvement_made = True\n",
        "        elif self.criterion == \"accuracy\":\n",
        "            if val_accuracy > self.best_val_accuracy + self.min_delta:\n",
        "                print(f\"new best accuracy: {val_accuracy:.4f}\")\n",
        "                self.best_val_accuracy = val_accuracy\n",
        "                self.epochs_without_improvement = 0\n",
        "                improvement_made = True\n",
        "\n",
        "        # If in cooldown mode no need to make any change yet\n",
        "        if self.cooldown_counter > 0:\n",
        "            print(\"You are in cooldown mode\")\n",
        "            self.cooldown_counter -= 1\n",
        "            return min_lr_reached\n",
        "\n",
        "        # No improvement\n",
        "        if not improvement_made:\n",
        "            self.epochs_without_improvement += 1\n",
        "            # If Maximum epochs without improvement reached\n",
        "            if self.epochs_without_improvement >= self.patience:\n",
        "                # Calculate new lr\n",
        "                # multiply current lr with the reduction factor\n",
        "                current_lr = current_lr * self.reduction_factor\n",
        "\n",
        "                if current_lr <= self.min_lr:\n",
        "                    min_lr_reached = True\n",
        "                    new_lr = self.min_lr\n",
        "                    print(f\"Minimum learning rate of {self.min_lr} reached\")\n",
        "                else:\n",
        "                    new_lr = current_lr\n",
        "\n",
        "                print(f\"Reducing learning rate to {new_lr}\")\n",
        "                self.model.optimizer.learning_rate.assign(new_lr)\n",
        "\n",
        "                # Reset epochs without improvement counter and enter cooldown\n",
        "                self.epochs_without_improvement = 0\n",
        "                print(\"Entering cooldown\")\n",
        "                self.cooldown_counter = self.cooldown_patience\n",
        "\n",
        "        return min_lr_reached\n",
        "\n",
        "\n",
        "\n",
        "class ReduceLrSteadilyCustom(keras.callbacks.Callback):\n",
        "    def __init__(self,model,reduction_factor,patience, patience_counter=0, min_lr=1e-5):\n",
        "        super(ReduceLrSteadilyCustom,self).__init__()\n",
        "        self.model = model\n",
        "        self.reduction_factor = reduction_factor\n",
        "        self.patience = patience\n",
        "        self.counter = patience_counter\n",
        "        self.min_lr = min_lr\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.counter += 1\n",
        "        current_lr = float(self.model.optimizer.learning_rate.numpy())\n",
        "        min_lr_reached = False\n",
        "\n",
        "        if current_lr <= self.min_lr:\n",
        "            print(\"Minimum lr already reached\")\n",
        "            return True\n",
        "        # If reached enough epochs\n",
        "        if self.counter >= self.patience:\n",
        "            current_lr = current_lr*self.reduction_factor\n",
        "\n",
        "            if current_lr <= self.min_lr:\n",
        "                print(f\"Minimum lr {self.min_lr:.6} reached\")\n",
        "                new_lr = self.min_lr\n",
        "                min_lr_reached = True\n",
        "            else:\n",
        "                new_lr = current_lr\n",
        "\n",
        "            print(f\"New lr value: {new_lr:.6f}\")\n",
        "            self.model.optimizer.learning_rate.assign(new_lr)\n",
        "            self.counter = 0\n",
        "\n",
        "        return min_lr_reached\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "cellView": "form",
        "id": "PmutXnRIttft"
      },
      "outputs": [],
      "source": [
        "# @title Flags\n",
        "\n",
        "LOAD_EXISTING_MODEL = False\n",
        "\n",
        "SAVE_MODEL = False\n",
        "\n",
        "# Callbacks\n",
        "LR_SCHEDULER_ENABLED = True\n",
        "CHECKPOINT_BEST_LOSS_ENABLED = False\n",
        "CHECKPOINT_BEST_ACC_ENABLED = True\n",
        "CHECKPOINT_LATEST_ENABLED = False\n",
        "SAVE_TRAIN_STATS_ENABLED = False\n",
        "\n",
        "EARLY_STOPPING_ENABLED = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "id": "nGJEBkao4f1T"
      },
      "outputs": [],
      "source": [
        "# @title Load training existing parameters\n",
        "\n",
        "def keep_result_lines_until_best(filepath, epoch_to_keep_until):\n",
        "    with open(filepath, 'r') as f_read:\n",
        "        lines = f_read.readlines()\n",
        "        lines_to_keep = lines[:2]\n",
        "        for line in lines[2:]:\n",
        "            if get_line_starting_number(line) <= epoch_to_keep_until: #TODO - Fix so that the whole number of the line is read\n",
        "                lines_to_keep.append(line)\n",
        "\n",
        "    with open(filepath, 'w') as f_write:\n",
        "        for line in lines_to_keep:\n",
        "            f_write.write(line)\n",
        "\n",
        "    return\n",
        "\n",
        "\"\"\"\n",
        "PARAMETERS\n",
        "    criterion : 'latest', 'best_loss' or 'best_acc'\n",
        "\"\"\"\n",
        "def get_training_config_from_json_file(json_filename,criterion):\n",
        "    # training parameters\n",
        "    global validation_steps\n",
        "    global training_steps\n",
        "    global batch_size\n",
        "\n",
        "    # optimizer\n",
        "    global optimizer\n",
        "    global learning_rate\n",
        "    global loss\n",
        "    global metrics\n",
        "    global starting_epoch\n",
        "\n",
        "    # processing\n",
        "    global preproc_config\n",
        "    global aug_enabled\n",
        "    global aug_config\n",
        "\n",
        "    # data generator\n",
        "    global data_intake\n",
        "    global db\n",
        "    global rms\n",
        "\n",
        "    # accuracy and loss\n",
        "    global best_val_loss\n",
        "    global best_val_accuracy\n",
        "\n",
        "    with open(json_filename) as f:\n",
        "        info = json.load(f)\n",
        "        # Processing\n",
        "        preproc_config  = info[\"PROCESSING\"][\"PREPROCESSING\"]\n",
        "        aug_enabled     = info[\"PROCESSING\"][\"AUG_ENABLED\"]\n",
        "        aug_config      = info[\"PROCESSING\"][\"AUGMENTATION\"]\n",
        "\n",
        "        # Training Info\n",
        "        training_steps   = info[\"TRAINING_INFO\"][\"ITERATIONS_PER_EPOCH\"]\n",
        "        validation_steps = info[\"TRAINING_INFO\"][\"VALIDATION_STEPS\"]\n",
        "        batch_size       = info[\"TRAINING_INFO\"][\"BATCH_SIZE\"]\n",
        "        optimizer_name   = info[\"TRAINING_INFO\"][\"OPTIMIZER\"]\n",
        "        loss             = info[\"TRAINING_INFO\"][\"LOSS\"]\n",
        "        metrics          = info[\"TRAINING_INFO\"][\"METRICS\"]\n",
        "        if 'loss' in metrics:\n",
        "            metrics.remove('loss')\n",
        "\n",
        "        # Results\n",
        "        best_val_accuracy = info[\"RESULTS\"][\"BEST_VAL_ACC\"]\n",
        "        best_val_loss = info[\"RESULTS\"][\"BEST_VAL_LOSS\"]\n",
        "        if criterion == \"latest\":\n",
        "            learning_rate = info[\"RESULTS\"][\"LATEST_EPOCH_LEARNING_RATE\"]\n",
        "            starting_epoch = info[\"RESULTS\"][\"TOTAL_EPOCHS\"]\n",
        "        elif criterion == \"best_acc\":\n",
        "            learning_rate = info[\"RESULTS\"][\"BEST_EPOCH_ACC_LEARNING_RATE\"]\n",
        "            starting_epoch = info[\"RESULTS\"][\"BEST_EPOCH_ACC\"]\n",
        "        elif criterion == \"best_loss\":\n",
        "            learning_rate = info[\"RESULTS\"][\"BEST_EPOCH_LOSS_LEARNING_RATE\"]\n",
        "            starting_epoch = info[\"RESULTS\"][\"BEST_EPOCH_LOSS\"]\n",
        "        else:\n",
        "            exit(\"Wrong 'criterion' input in get_training_config_from_json_file()\")\n",
        "\n",
        "        # Data generator\n",
        "        data_intake = info[\"DATA_GENERATOR\"][\"DATA_INTAKE\"]\n",
        "        db          = info[\"DATA_GENERATOR\"][\"DB\"]\n",
        "        rms         = info[\"DATA_GENERATOR\"][\"RMS\"]\n",
        "\n",
        "        if optimizer_name == 'Adam':\n",
        "            optimizer = keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "    return\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-8t24IeGd2g"
      },
      "source": [
        "# 9 - PROTOTYPICAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bPIc81zolCF2"
      },
      "outputs": [],
      "source": [
        "# @title Hardcoded training parameters (for new model)\n",
        "\n",
        "validation_steps = 10000\n",
        "training_steps = 1000\n",
        "starting_epoch = 0\n",
        "batch_size = 64\n",
        "epochs = 25\n",
        "win_size = 15\n",
        "channels = 12\n",
        "inp_shape = (win_size,channels,1)\n",
        "cnn_backbone = AtzoriNetDB2_embedding_only_extra_layers_added(input_shape=inp_shape, add_dropout=False, add_regularizer=False, extra_layers=3)\n",
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.Adam(learning_rate)\n",
        "loss_function = 'categorical_crossentropy'\n",
        "metrics = ['categorical_accuracy']\n",
        "\n",
        "#input shape tuple\n",
        "inp_shape_5d = (None,) + inp_shape\n",
        "\n",
        "# DB and rms\n",
        "db = 2\n",
        "rms = 100\n",
        "\n",
        "# experiment, way, shot\n",
        "ex = '1'\n",
        "N = 5\n",
        "k = 5\n",
        "\n",
        "\n",
        "# Results\n",
        "best_val_loss = float('inf')\n",
        "best_val_accuracy = 0.0\n",
        "\n",
        "#cnn_backbone = AtzoriNetDB2_embedding_only()\n",
        "cnn_backbone = AtzoriNetDB2_embedding_only_extra_layers_added(extra_layers=3)\n",
        "\n",
        "resultsPath = get_results_dir_fullpath(ex, N, k)\n",
        "\n",
        "# In case of LOAD_EXISTING_MODEL == True\n",
        "model_name = 'model_ProtoNet_8'\n",
        "criterion = 'best_loss'\n",
        "#criterion = 'best_acc'\n",
        "# criterion = 'latest'\n",
        "\n",
        "\n",
        "if not LOAD_EXISTING_MODEL:\n",
        "    print(\"Creating new model...\\n\")\n",
        "    model = assemble_protonet_reshape_with_batch(cnn_backbone, inp_shape, way=N, shot=k)\n",
        "    model.compile(loss=loss_function, optimizer=optimizer, metrics=metrics)\n",
        "    model_foldername = get_checkpoint_foldername(resultsPath, model.name)\n",
        "    print(\"Name:\",model.name,'\\n')\n",
        "\n",
        "    #Results\n",
        "    resultsPath = os.path.join(resultsPath, model_foldername)\n",
        "    os.mkdir(resultsPath)\n",
        "    checkpoint_latest_path = os.path.join(resultsPath, get_model_checkpoint_fullname(model_foldername, criterion='latest'))\n",
        "    checkpoint_best_acc_path = os.path.join(resultsPath, get_model_checkpoint_fullname(model_foldername, criterion='best_acc'))\n",
        "    checkpoint_best_loss_path = os.path.join(resultsPath, get_model_checkpoint_fullname(model_foldername, criterion='best_loss'))\n",
        "\n",
        "    # Save initial state for all 3 models\n",
        "    model.save(checkpoint_latest_path)\n",
        "    model.save(checkpoint_best_loss_path)\n",
        "    model.save(checkpoint_best_acc_path)\n",
        "\n",
        "    print(f\"...model saved at '{resultsPath}'\")\n",
        "\n",
        "else:\n",
        "    print(\"Loading existing model...\\n\")\n",
        "    print(f\"Name: {model_name}\\n\")\n",
        "    print(f\"Criterion: {criterion}\\n\")\n",
        "\n",
        "    model_foldername = model_name\n",
        "\n",
        "    # Results paths\n",
        "    resultsPath = os.path.join(resultsPath, model_foldername)\n",
        "    checkpoint_latest_path = os.path.join(resultsPath, get_model_checkpoint_fullname(model_foldername, criterion='latest'))\n",
        "    checkpoint_best_acc_path = os.path.join(resultsPath, get_model_checkpoint_fullname(model_foldername, criterion='best_acc'))\n",
        "    checkpoint_best_loss_path = os.path.join(resultsPath, get_model_checkpoint_fullname(model_foldername, criterion='best_loss'))\n",
        "\n",
        "    load_model_fullpath = {\"latest\":checkpoint_latest_path, \"best_acc\":checkpoint_best_acc_path, \"best_loss\":checkpoint_best_loss_path}[criterion]\n",
        "\n",
        "    get_training_config_from_json_file(os.path.join(resultsPath,model_foldername + \"_training_info.json\"),criterion)\n",
        "    keep_result_lines_until_best(filepath=os.path.join(resultsPath,model_foldername + \"_results.txt\"),epoch_to_keep_until=starting_epoch)\n",
        "    print(f\"...model loaded. Resuming training from epoch {starting_epoch}\")\n",
        "\n",
        "    model = keras.models.load_model(load_model_fullpath)\n",
        "    model.compile(loss=loss_function, optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "\n",
        "preproc_config = get_config_from_json_file('preproc', 'db2_no_discard_lpf_minmax_muLaw')\n",
        "\n",
        "aug_enabled = True\n",
        "aug_config = get_config_from_json_file('aug', 'db2_awgn_snr25')\n",
        "data_intake = 'generate'\n",
        "\n",
        "data_loader = TaskGenerator(experiment=ex, way=N, shot=k, mode='train', data_intake=data_intake, database=db, preprocessing_config=preproc_config, aug_enabled=aug_enabled, aug_config=aug_config, rms_win_size=rms, batch_size=batch_size, batches=training_steps, print_labels=True, print_labels_frequency=5)\n",
        "\n",
        "# Getting 1 output from train loader to test dimensions etc\n",
        "[x,y], label = data_loader[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yh5Lm9wz-bht"
      },
      "outputs": [],
      "source": [
        "# @title Training Callbacks\n",
        "\n",
        "# Logger\n",
        "iterationLoggingCallback = IterationLoggingCallback()\n",
        "\n",
        "# Checkpoint\n",
        "checkpointCallBack_val_loss = ModelCheckpoint(checkpoint_best_loss_path, save_best_only=True, monitor='val_loss', mode='min')\n",
        "checkpointCallBack_val_loss.set_model(model)\n",
        "\n",
        "checkpointCallBack_val_acc = ModelCheckpoint(checkpoint_best_acc_path, save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "checkpointCallBack_val_acc.set_model(model)\n",
        "\n",
        "checkpointCallBack_latest = ModelCheckpoint(checkpoint_latest_path, save_freq='epoch')\n",
        "checkpointCallBack_latest.set_model(model)\n",
        "\n",
        "# Training info\n",
        "trainingInfoCallback = TrainingInfoCallback(resultsPath, model, batch_size, model_foldername, cnn_backbone.name, ex, training_steps, validation_steps, preproc_config, aug_enabled, aug_config, data_intake, rms, db)\n",
        "\n",
        "# LR Adjustment\n",
        "reduction_factor = 0.5\n",
        "patience = 2\n",
        "cooldown_patience = 2\n",
        "min_lr = 1e-4\n",
        "min_delta = 0.001\n",
        "lr_adjustment_callback = ReduceLrOnPlateauCustom(model=model, reduction_factor=reduction_factor, patience=patience,cooldown_patience=cooldown_patience,min_lr=min_lr, min_delta=min_delta, best_val_loss=best_val_loss)\n",
        "#lr_adjustment_callback = ReduceLrSteadilyCustom(model=model, reduction_factor=reduction_factor,patience=patience,min_lr=min_lr)\n",
        "\n",
        "\n",
        "early_stopping_mode_on = EARLY_STOPPING_ENABLED and (not LR_SCHEDULER_ENABLED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rSXCaFrBbncQ",
        "outputId": "3fdbddb5-c346-48e3-810a-a3b278fa1697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  1/25\n",
            "1000/1000 [==============================] - 198s 196ms/step - loss: 1.2480 - categorical_accuracy: 0.4621\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 1.1918 - categorical_accuracy: 0.4957\n",
            "new best loss 1.1918\n",
            "\n",
            "Epoch  2/25\n",
            "1000/1000 [==============================] - 186s 186ms/step - loss: 1.1216 - categorical_accuracy: 0.5260\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 1.0888 - categorical_accuracy: 0.5454\n",
            "new best loss 1.0888\n",
            "\n",
            "Epoch  3/25\n",
            "1000/1000 [==============================] - 186s 186ms/step - loss: 1.0502 - categorical_accuracy: 0.5607\n",
            "Validation\n",
            "10000/10000 [==============================] - 47s 5ms/step - loss: 1.0375 - categorical_accuracy: 0.5745\n",
            "new best loss 1.0375\n",
            "\n",
            "Epoch  4/25\n",
            "1000/1000 [==============================] - 184s 184ms/step - loss: 1.0080 - categorical_accuracy: 0.5818\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 1.0049 - categorical_accuracy: 0.5881\n",
            "new best loss 1.0049\n",
            "\n",
            "Epoch  5/25\n",
            "1000/1000 [==============================] - 183s 183ms/step - loss: 0.9656 - categorical_accuracy: 0.6005\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.9802 - categorical_accuracy: 0.5905\n",
            "new best loss 0.9802\n",
            "\n",
            "Epoch  6/25\n",
            "1000/1000 [==============================] - 186s 186ms/step - loss: 0.9274 - categorical_accuracy: 0.6203\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.9455 - categorical_accuracy: 0.6058\n",
            "new best loss 0.9455\n",
            "\n",
            "Epoch  7/25\n",
            "1000/1000 [==============================] - 189s 188ms/step - loss: 0.8995 - categorical_accuracy: 0.6280\n",
            "Validation\n",
            "10000/10000 [==============================] - 47s 5ms/step - loss: 0.9401 - categorical_accuracy: 0.6149\n",
            "new best loss 0.9401\n",
            "\n",
            "Epoch  8/25\n",
            "1000/1000 [==============================] - 184s 183ms/step - loss: 0.8760 - categorical_accuracy: 0.6449\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.9058 - categorical_accuracy: 0.6262\n",
            "new best loss 0.9058\n",
            "\n",
            "Epoch  9/25\n",
            "1000/1000 [==============================] - 189s 189ms/step - loss: 0.8489 - categorical_accuracy: 0.6531\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.8860 - categorical_accuracy: 0.6358\n",
            "new best loss 0.8860\n",
            "\n",
            "Epoch 10/25\n",
            "1000/1000 [==============================] - 191s 191ms/step - loss: 0.8332 - categorical_accuracy: 0.6610\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.8843 - categorical_accuracy: 0.6385\n",
            "new best loss 0.8843\n",
            "\n",
            "Epoch 11/25\n",
            "1000/1000 [==============================] - 193s 193ms/step - loss: 0.8074 - categorical_accuracy: 0.6709\n",
            "Validation\n",
            "10000/10000 [==============================] - 47s 5ms/step - loss: 0.8722 - categorical_accuracy: 0.6487\n",
            "new best loss 0.8722\n",
            "\n",
            "Epoch 12/25\n",
            "1000/1000 [==============================] - 192s 192ms/step - loss: 0.7974 - categorical_accuracy: 0.6748\n",
            "Validation\n",
            "10000/10000 [==============================] - 45s 5ms/step - loss: 0.8597 - categorical_accuracy: 0.6490\n",
            "new best loss 0.8597\n",
            "\n",
            "Epoch 13/25\n",
            "1000/1000 [==============================] - 193s 193ms/step - loss: 0.7866 - categorical_accuracy: 0.6813\n",
            "Validation\n",
            "10000/10000 [==============================] - 45s 5ms/step - loss: 0.8440 - categorical_accuracy: 0.6574\n",
            "new best loss 0.8440\n",
            "\n",
            "Epoch 14/25\n",
            "1000/1000 [==============================] - 197s 197ms/step - loss: 0.7648 - categorical_accuracy: 0.6899\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.8150 - categorical_accuracy: 0.6740\n",
            "new best loss 0.8150\n",
            "\n",
            "Epoch 15/25\n",
            "1000/1000 [==============================] - 198s 198ms/step - loss: 0.7528 - categorical_accuracy: 0.6935\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.8274 - categorical_accuracy: 0.6674\n",
            "\n",
            "Epoch 16/25\n",
            "1000/1000 [==============================] - 197s 197ms/step - loss: 0.7403 - categorical_accuracy: 0.6985\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.8075 - categorical_accuracy: 0.6713\n",
            "new best loss 0.8075\n",
            "\n",
            "Epoch 17/25\n",
            "1000/1000 [==============================] - 194s 194ms/step - loss: 0.7274 - categorical_accuracy: 0.7080\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.8042 - categorical_accuracy: 0.6775\n",
            "new best loss 0.8042\n",
            "\n",
            "Epoch 18/25\n",
            "1000/1000 [==============================] - 197s 196ms/step - loss: 0.7236 - categorical_accuracy: 0.7086\n",
            "Validation\n",
            "10000/10000 [==============================] - 45s 5ms/step - loss: 0.7911 - categorical_accuracy: 0.6826\n",
            "new best loss 0.7911\n",
            "\n",
            "Epoch 19/25\n",
            "1000/1000 [==============================] - 193s 193ms/step - loss: 0.7063 - categorical_accuracy: 0.7156\n",
            "Validation\n",
            "10000/10000 [==============================] - 45s 5ms/step - loss: 0.7969 - categorical_accuracy: 0.6843\n",
            "\n",
            "Epoch 20/25\n",
            "1000/1000 [==============================] - 188s 188ms/step - loss: 0.7002 - categorical_accuracy: 0.7190\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.7776 - categorical_accuracy: 0.6884\n",
            "new best loss 0.7776\n",
            "\n",
            "Epoch 21/25\n",
            "1000/1000 [==============================] - 187s 187ms/step - loss: 0.6933 - categorical_accuracy: 0.7240\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.8003 - categorical_accuracy: 0.6805\n",
            "\n",
            "Epoch 22/25\n",
            "1000/1000 [==============================] - 188s 188ms/step - loss: 0.6810 - categorical_accuracy: 0.7266\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.7740 - categorical_accuracy: 0.6888\n",
            "new best loss 0.7740\n",
            "\n",
            "Epoch 23/25\n",
            "1000/1000 [==============================] - 187s 187ms/step - loss: 0.6796 - categorical_accuracy: 0.7271\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.7624 - categorical_accuracy: 0.6970\n",
            "new best loss 0.7624\n",
            "\n",
            "Epoch 24/25\n",
            "1000/1000 [==============================] - 185s 185ms/step - loss: 0.6641 - categorical_accuracy: 0.7358\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.7504 - categorical_accuracy: 0.6971\n",
            "new best loss 0.7504\n",
            "\n",
            "Epoch 25/25\n",
            "1000/1000 [==============================] - 187s 187ms/step - loss: 0.6608 - categorical_accuracy: 0.7352\n",
            "Validation\n",
            "10000/10000 [==============================] - 46s 5ms/step - loss: 0.7856 - categorical_accuracy: 0.6895\n"
          ]
        }
      ],
      "source": [
        "# @title Training Loop\n",
        "\n",
        "for epoch_num in range(starting_epoch, starting_epoch+epochs):\n",
        "    # training\n",
        "    data_loader.setMode('train')\n",
        "    data_loader.set_iterations_per_epoch(training_steps)\n",
        "    data_loader.set_batch_size(batch_size)\n",
        "    data_loader.set_aug_enabled(aug_enabled)\n",
        "    print(f\"\\nEpoch {epoch_num+1:2d}/{starting_epoch+epochs}\")\n",
        "\n",
        "    # train for 1 epoch\n",
        "    history = model.fit(data_loader, epochs=1, shuffle=False, callbacks=[iterationLoggingCallback])\n",
        "\n",
        "    # validation\n",
        "    if ex == '1':\n",
        "      data_loader.setMode('test')\n",
        "    else:\n",
        "      data_loader.setMode('val')\n",
        "\n",
        "    data_loader.set_iterations_per_epoch(validation_steps)\n",
        "    data_loader.set_batch_size(1)\n",
        "    data_loader.set_aug_enabled(False)\n",
        "    print(\"Validation\")\n",
        "    val_loss, val_accuracy = model.evaluate(data_loader)\n",
        "    logs = {\"val_accuracy\": val_accuracy, \"val_loss\": val_loss}\n",
        "\n",
        "    # Model checkpoint: save model if it has the best performance\n",
        "    if(val_loss < best_val_loss):\n",
        "        best_val_loss = val_loss\n",
        "        checkpointCallBack_val_loss.on_epoch_end(epoch_num, logs)\n",
        "\n",
        "        trainingInfoCallback.best_val_loss = best_val_loss\n",
        "        trainingInfoCallback.best_epoch_val_loss = epoch_num+1\n",
        "        trainingInfoCallback.best_loss_lr = float(model.optimizer.learning_rate.numpy())\n",
        "\n",
        "    if(val_accuracy > best_val_accuracy):\n",
        "        best_val_accuracy = val_accuracy\n",
        "        checkpointCallBack_val_acc.on_epoch_end(epoch_num,logs)\n",
        "\n",
        "        trainingInfoCallback.best_val_acc = best_val_accuracy\n",
        "        trainingInfoCallback.best_epoch_val_acc = epoch_num+1\n",
        "        trainingInfoCallback.best_acc_lr = float(model.optimizer.learning_rate.numpy())\n",
        "\n",
        "    checkpointCallBack_latest.on_epoch_end(epoch_num, logs)\n",
        "\n",
        "    # Write results\n",
        "    train_results = dict(**{\"train_accuracy\" : history.history['categorical_accuracy'][0], 'train_loss' : history.history['loss'][0]},**logs)\n",
        "    trainingInfoCallback.on_epoch_end(epoch=epoch_num, logs=train_results)\n",
        "\n",
        "    if LR_SCHEDULER_ENABLED:\n",
        "        min_lr_reached = lr_adjustment_callback.on_epoch_end(epoch_num,logs)\n",
        "\n",
        "        if min_lr_reached and EARLY_STOPPING_ENABLED:\n",
        "            early_stopping_mode_on = True\n",
        "\n",
        "    if early_stopping_mode_on:\n",
        "        continue\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J5c255Rbj0y",
        "outputId": "276b294b-9217-466d-9ff9-8366f591201b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "20000/20000 [==============================] - 94s 5ms/step - loss: 1.3469 - categorical_accuracy: 0.4794\n",
            "test_loss: 1.346850872039795\n",
            "test_accuracy 0.4793500006198883\n"
          ]
        }
      ],
      "source": [
        "# @title Test\n",
        "\n",
        "data_loader.setMode('test')\n",
        "data_loader.set_iterations_per_epoch(20000)\n",
        "data_loader.set_batch_size(1)\n",
        "data_loader.set_aug_enabled(False)\n",
        "print(\"Test\")\n",
        "test_loss, test_accuracy = model.evaluate(data_loader)\n",
        "print('test_loss:',test_loss)\n",
        "print('test_accuracy',test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs5Aj333oO2w",
        "outputId": "4ae81173-0285-4c80-83cc-28bfd2211a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "# @title GPU info\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXpzEXMBG-vr"
      },
      "source": [
        "# 10 - SIAMESE NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "e710ae61ef254b1fa8df4d209e05441c",
            "f1f7e37587e7464bb6fc83e2dccf603e",
            "e9fe3773f7c5479b832dfbbed2c9b3d2",
            "0726fdc9dfbe4589af1a41a1937a0b95",
            "bf1a7623d230436a92b289d3aa940699",
            "3902a3ea5f1f42108f9537866312e8f0",
            "23c218b7a8254ee8b0c5c631d0555c4d",
            "630d88caf8b5444ea18327162d69e124",
            "dd71a8d9387c434694dabaf5e1e28a94",
            "f0c7df2622cc4865b32738533e943b29",
            "5bf00159cf764620afb003be34a96304",
            "bbe7f9e86c1649daba5a308983553380",
            "458ea1863e87427c9c4608b7cad4c33d",
            "7f537bf377cb46f6b0e9be120ac2b983",
            "e37c1fe1df264d00ada64279e920e949",
            "3ffdee5cfbd3495f8817f272b39e2832",
            "27bbc41196da431fbca54a7f9c343e8e",
            "c14fb51b4f2749f181997c9f5d60f2b0",
            "9d41687e8fad45fb9f49981cdec45758",
            "68daed86d0414c128db7c33f065c5845",
            "79667e7df5b14808be3421fbc04d6295",
            "bfec288288c946d29d7d1a88dafe9da5",
            "8d4b27809aef466fb035d2d0ad358b6c",
            "66cbb7407663443798a547f25a1ea1ad",
            "11ea4d4688aa4c37aa6e69113eb63b3d",
            "8f2e2565ec8e42569ebe41cf18fd0897",
            "15a3e65ca9104e7abf8a2e2c2176d34d",
            "1e867fee068148cc8fc42a86ba8e2cdf",
            "ffe41b37dfe14b49a0e7e5b6765e48ff",
            "a6beb5d5b814454cbfb8350d42eab23a",
            "a1201fc638b9402485eee301981c3e96",
            "155cf3fa8ef14859bc90393043cda238",
            "7d1bebb4be7f4464b67f8d19d1e8cec3"
          ],
          "height": 1000
        },
        "id": "nPuKcYJzHMtt",
        "outputId": "1a79d763-6aab-42d9-c265-57ec48c3ad0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new model...\n",
            "\n",
            "~~~ TRAIN LOADER ~~~\n",
            "Data processing...\n",
            "...loading the data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preprocessing:   0%|          | 0/40 [00:00<?, ? reps/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e710ae61ef254b1fa8df4d209e05441c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing Data Augmentation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Augmentation:   0%|          | 0/40 [00:00<?, ? reps/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbe7f9e86c1649daba5a308983553380"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "~~~ TEST LOADER ~~~\n",
            "Data processing...\n",
            "...loading the data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preprocessing:   0%|          | 0/40 [00:00<?, ? reps/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d4b27809aef466fb035d2d0ad358b6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "epoch 1/80\n",
            "Training\n",
            "2000/2000 [==============================] - 42s 20ms/step - loss: 0.6651 - binary_accuracy: 0.5851\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.2437 - categorical_accuracy: 0.3934\n",
            "\n",
            "epoch 2/80\n",
            "Training\n",
            "2000/2000 [==============================] - 40s 20ms/step - loss: 0.6287 - binary_accuracy: 0.6372\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.2191 - categorical_accuracy: 0.4150\n",
            "\n",
            "epoch 3/80\n",
            "Training\n",
            "2000/2000 [==============================] - 40s 20ms/step - loss: 0.6130 - binary_accuracy: 0.6568\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1998 - categorical_accuracy: 0.4564\n",
            "\n",
            "epoch 4/80\n",
            "Training\n",
            "2000/2000 [==============================] - 40s 20ms/step - loss: 0.6024 - binary_accuracy: 0.6667\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1869 - categorical_accuracy: 0.4932\n",
            "\n",
            "epoch 5/80\n",
            "Training\n",
            "2000/2000 [==============================] - 40s 20ms/step - loss: 0.5941 - binary_accuracy: 0.6754\n",
            "Validation\n",
            "5000/5000 [==============================] - 25s 5ms/step - loss: 0.2034 - categorical_accuracy: 0.4818\n",
            "\n",
            "epoch 6/80\n",
            "Training\n",
            "2000/2000 [==============================] - 40s 20ms/step - loss: 0.5862 - binary_accuracy: 0.6817\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1882 - categorical_accuracy: 0.5078\n",
            "\n",
            "epoch 7/80\n",
            "Training\n",
            "2000/2000 [==============================] - 41s 20ms/step - loss: 0.5766 - binary_accuracy: 0.6907\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1864 - categorical_accuracy: 0.5312\n",
            "\n",
            "epoch 8/80\n",
            "Training\n",
            "2000/2000 [==============================] - 41s 21ms/step - loss: 0.5681 - binary_accuracy: 0.6981\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1759 - categorical_accuracy: 0.5452\n",
            "\n",
            "epoch 9/80\n",
            "Training\n",
            "2000/2000 [==============================] - 41s 20ms/step - loss: 0.5619 - binary_accuracy: 0.7051\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1965 - categorical_accuracy: 0.5364\n",
            "\n",
            "epoch 10/80\n",
            "Training\n",
            "2000/2000 [==============================] - 40s 20ms/step - loss: 0.5567 - binary_accuracy: 0.7077\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1811 - categorical_accuracy: 0.5390\n",
            "\n",
            "epoch 11/80\n",
            "Training\n",
            "2000/2000 [==============================] - 40s 20ms/step - loss: 0.5512 - binary_accuracy: 0.7139\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1799 - categorical_accuracy: 0.5740\n",
            "\n",
            "epoch 12/80\n",
            "Training\n",
            "2000/2000 [==============================] - 40s 20ms/step - loss: 0.5441 - binary_accuracy: 0.7183\n",
            "Validation\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.1624 - categorical_accuracy: 0.5730\n",
            "\n",
            "epoch 13/80\n",
            "Training\n",
            " 262/2000 [==>...........................] - ETA: 34s - loss: 0.5383 - binary_accuracy: 0.7254"
          ]
        }
      ],
      "source": [
        "# @title Train SiamNet\n",
        "\n",
        "def run_callbacks():\n",
        "    logs = {\"val_accuracy\": val_accuracy, \"val_loss\": val_loss}\n",
        "    early_stopping_mode_on = False\n",
        "\n",
        "    if SAVE_MODEL == True:\n",
        "        if CHECKPOINT_LATEST_ENABLED:    #TODO\n",
        "            pass\n",
        "        if CHECKPOINT_BEST_LOSS_ENABLED: #TODO\n",
        "            pass\n",
        "        if CHECKPOINT_BEST_ACC_ENABLED:  #TODO\n",
        "            pass\n",
        "        if SAVE_TRAIN_STATS_ENABLED:     #TODO\n",
        "            train_results = dict(\n",
        "                **{\"train_accuracy\": history.history['categorical_accuracy'][0], 'train_loss': history.history['loss'][0]},\n",
        "                **logs)\n",
        "            # trainingInfoCallback.on_epoch_end(epoch=epoch_num, logs=train_results)\n",
        "\n",
        "    if LR_SCHEDULER_ENABLED:\n",
        "        min_lr_reached = lr_adjustment_callback.on_epoch_end(epoch_num, logs)\n",
        "\n",
        "        if min_lr_reached and EARLY_STOPPING_ENABLED:\n",
        "            early_stopping_mode_on = True\n",
        "\n",
        "    if EARLY_STOPPING_ENABLED and early_stopping_mode_on:\n",
        "        pass\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    # For the correct class (where y_true == 1), we want the similarity score to be close to 1\n",
        "    positive_loss = y_true * K.square(1 - y_pred)\n",
        "\n",
        "    # For the incorrect classes (where y_true == 0), we want the similarity score to be close to 0\n",
        "    negative_loss = (1 - y_true) * K.square(y_pred)\n",
        "\n",
        "    # Combine the positive and negative losses and average over all classes\n",
        "    loss = K.mean(positive_loss + negative_loss)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def evaluate_model(model:SiameseNetwork, data_loader, N):\n",
        "    model_val = assemble_siamNet_for_few_shot_infernce(model=model, inp_shape=inp_shape, N=N)\n",
        "    loss1 = 'categorical_crossentropy'\n",
        "    loss2 = contrastive_loss\n",
        "    model_val.compile(optimizer, loss=loss2, metrics=['categorical_accuracy'])\n",
        "    print(\"Validation\")\n",
        "    val_loss, val_accuracy = model_val.evaluate(data_loader)\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "\n",
        "def evaluate_model2(model:SiameseNetwork, data_loader, validation_steps, N):\n",
        "    # model.compile(optimizer=optimizer, loss=contrastive_loss, metrics=['categorical_accuracy'])\n",
        "    inp_support_set = layers.Input(shape=(None,) + inp_shape)\n",
        "    feature_extractor = model.feature_extractor\n",
        "    feature_extractor_timeDist = keras.Model(inputs = inp_support_set, outputs=TimeDistributed(feature_extractor)(inp_support_set))\n",
        "\n",
        "    dense_layers = model.dense_layers\n",
        "    f = model.f\n",
        "\n",
        "    correct_predictions = 0\n",
        "\n",
        "    accuracy = 0.0\n",
        "\n",
        "    progress_bar = tqdm(total=validation_steps, desc=\"Validation\", unit=\" iterations\")\n",
        "\n",
        "    for i in range(validation_steps):\n",
        "        [support_set, query_image], labels = data_loader[i]\n",
        "        # This is done because the support and the query image are taken in batches of 1\n",
        "        support_set = support_set[0]\n",
        "        query_image = query_image[0]\n",
        "\n",
        "        # This produces a single L-long vector (where L is the chosen embedding shape for the feature extractor ie 64)\n",
        "        query_embedding = feature_extractor(query_image)\n",
        "        # We copy the embedding N times (as many as the classes of the suport set)\n",
        "        # Input shape : (1,L) -> Output shape (N,L)\n",
        "        query_embedding_copied = tf.tile(query_embedding, [N,1])\n",
        "\n",
        "        # This produces a N,k set of L-long vectors\n",
        "        support_embeddings = feature_extractor_timeDist(support_set)\n",
        "        # Computes the prototypes of the classes that will go through the distance function\n",
        "        # Input shape: (N,k,L) -> Output shape : (N,L)\n",
        "        class_prototypes = produce_prototype(support_embeddings)\n",
        "\n",
        "        # The distance function applied to the two (N,L) sets to produce a single output of N vectors of length L\n",
        "        out_dist = f([query_embedding_copied, class_prototypes])\n",
        "\n",
        "        # Final prediction after passing the output of the distance function through the dense layers\n",
        "        pred = dense_layers(out_dist)\n",
        "\n",
        "        if np.argmax(pred) == np.argmax(labels):\n",
        "            correct_predictions += 1\n",
        "\n",
        "        accuracy = correct_predictions/(i+1)\n",
        "        progress_bar.set_postfix(accuracy=f\"{accuracy:.4f}\")\n",
        "        progress_bar.update(1)  # Update progress bar by 1\n",
        "\n",
        "    # progress_bar.close()\n",
        "\n",
        "    return\n",
        "\n",
        "training_steps = 2000\n",
        "validation_steps = 5000\n",
        "starting_epoch = 0\n",
        "batch_size = 64\n",
        "epochs = 80\n",
        "win_size = 15\n",
        "channels = 12\n",
        "inp_shape = (win_size,channels,1)\n",
        "learning_rate = 0.001\n",
        "optimizer = keras.optimizers.Adam(learning_rate)\n",
        "# loss_function = 'categorical_crossentropy'\n",
        "loss_function = 'binary_crossentropy'\n",
        "# metrics = ['categorical_accuracy']\n",
        "metrics = ['binary_accuracy']\n",
        "\n",
        "\n",
        "# DB and rms\n",
        "db = 2\n",
        "rms = 100\n",
        "\n",
        "# experiment, way, shot\n",
        "ex = '1'\n",
        "N = 5\n",
        "k = 5\n",
        "\n",
        "# Results\n",
        "best_val_loss = float('inf')\n",
        "best_val_accuracy = 0.0\n",
        "\n",
        "# LR Scheduler Parameters\n",
        "reduction_factor = 0.5\n",
        "patience = 25\n",
        "cooldown_patience = 2\n",
        "min_lr = 1e-4\n",
        "min_delta = 0.001\n",
        "\n",
        "cnn_backbone = AtzoriNetDB2_embedding_only_extra_layers_added(input_shape=inp_shape, extra_layers=3, add_dropout=False, add_regularizer=False)\n",
        "\n",
        "resultsPath = os.path.join(RESULTS_DIRECTORIES_DICT[ex], get_results_dir_fullpath(ex, N, k))\n",
        "\n",
        "print(\"Creating new model...\\n\")\n",
        "# model = assemble_protonet_reshape_with_batch(cnn_backbone, inp_shape, way=N, shot=k)\n",
        "model = SiameseNetwork(cnn_backbone=cnn_backbone, f=inner_product, inp_shape=inp_shape, dense_layers=get_dense_layers(neurons_per_layer=[]))\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "model_foldername = get_checkpoint_foldername(resultsPath, model.name)\n",
        "\n",
        "#Results\n",
        "resultsPath = os.path.join(resultsPath, model_foldername)\n",
        "if SAVE_MODEL == True:\n",
        "    # os.mkdir(resultsPath)\n",
        "    pass\n",
        "\n",
        "checkpoint_latest_path = os.path.join(resultsPath, get_model_checkpoint_fullname(model_foldername, criterion='latest'))\n",
        "checkpoint_best_acc_path = os.path.join(resultsPath, get_model_checkpoint_fullname(model_foldername, criterion='best_acc'))\n",
        "checkpoint_best_loss_path = os.path.join(resultsPath, get_model_checkpoint_fullname(model_foldername, criterion='best_loss'))\n",
        "\n",
        "# print(f\"...model saved at '{resultsPath}'\")\n",
        "\n",
        "\n",
        "preproc_config = get_config_from_json_file('preproc', \"db2_discard_3.5_lpf_minmax_no_muLaw\")\n",
        "aug_enabled = True\n",
        "aug_config = get_config_from_json_file('aug', 'db2_awgn_snr25')\n",
        "data_intake = 'generate'\n",
        "# network_type = \"protoNet\"\n",
        "network_type = \"siamNet\"\n",
        "\n",
        "\n",
        "train_loader = TaskGenerator(network_type=network_type, experiment=ex, way=N, shot=k, mode='train', data_intake=data_intake, database=db, preprocessing_config=preproc_config, aug_enabled=aug_enabled, aug_config=aug_config, rms_win_size=rms, batch_size=batch_size, batches=training_steps)\n",
        "test_loader = TaskGenerator(network_type='protoNet', experiment=ex, way=N, shot=k, mode='test', data_intake='generate', database=db, preprocessing_config=preproc_config, aug_enabled=False, aug_config=aug_config, rms_win_size=rms, batch_size=1, batches=validation_steps)\n",
        "\n",
        "# Getting 1 output from train loader to test dimensions etc\n",
        "[x,y], label = train_loader[0]\n",
        "[x2,y2], label2 = test_loader[0]\n",
        "\n",
        "\n",
        "# Custom Callbacks\n",
        "# lr_adjustment_callback = ReduceLrOnPlateauCustom(model=model, criterion=\"loss\", reduction_factor=reduction_factor, patience=patience,cooldown_patience=cooldown_patience,min_lr=min_lr, min_delta=min_delta, best_val_loss=best_val_loss, best_val_accuracy=best_val_accuracy)\n",
        "lr_adjustment_callback = ReduceLrSteadilyCustom(model=model, reduction_factor=reduction_factor,patience=patience,min_lr=min_lr)\n",
        "# checkpointCallBack_val_acc = ModelCheckpoint(checkpoint_best_acc_path, save_best_only=True, monitor='val_accuracy', mode='min')\n",
        "# checkpointCallBack_val_acc.set_model(model)\n",
        "\n",
        "for epoch_num in range(starting_epoch, starting_epoch+epochs):\n",
        "    print(f\"\\nepoch {epoch_num + 1}/{starting_epoch + epochs}\")\n",
        "    print(\"Training\")\n",
        "    history = model.fit(train_loader,epochs=1)\n",
        "    val_loss, val_accuracy = evaluate_model(model, test_loader, N)\n",
        "    run_callbacks()\n",
        "\n",
        "print()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "jEWqBbpav0ht",
        "MbXU2DSrwU_Y",
        "pTnhhqbUxBz7",
        "fMNeTAUuwzW3"
      ],
      "gpuType": "V28",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPKsqjAhve5XFlv1FklV1yP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e710ae61ef254b1fa8df4d209e05441c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1f7e37587e7464bb6fc83e2dccf603e",
              "IPY_MODEL_e9fe3773f7c5479b832dfbbed2c9b3d2",
              "IPY_MODEL_0726fdc9dfbe4589af1a41a1937a0b95"
            ],
            "layout": "IPY_MODEL_bf1a7623d230436a92b289d3aa940699"
          }
        },
        "f1f7e37587e7464bb6fc83e2dccf603e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3902a3ea5f1f42108f9537866312e8f0",
            "placeholder": "​",
            "style": "IPY_MODEL_23c218b7a8254ee8b0c5c631d0555c4d",
            "value": "Preprocessing: 100%"
          }
        },
        "e9fe3773f7c5479b832dfbbed2c9b3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_630d88caf8b5444ea18327162d69e124",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd71a8d9387c434694dabaf5e1e28a94",
            "value": 40
          }
        },
        "0726fdc9dfbe4589af1a41a1937a0b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0c7df2622cc4865b32738533e943b29",
            "placeholder": "​",
            "style": "IPY_MODEL_5bf00159cf764620afb003be34a96304",
            "value": " 40/40 [00:02&lt;00:00, 19.71 reps/s, subject=s40]"
          }
        },
        "bf1a7623d230436a92b289d3aa940699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3902a3ea5f1f42108f9537866312e8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c218b7a8254ee8b0c5c631d0555c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "630d88caf8b5444ea18327162d69e124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd71a8d9387c434694dabaf5e1e28a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0c7df2622cc4865b32738533e943b29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf00159cf764620afb003be34a96304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbe7f9e86c1649daba5a308983553380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_458ea1863e87427c9c4608b7cad4c33d",
              "IPY_MODEL_7f537bf377cb46f6b0e9be120ac2b983",
              "IPY_MODEL_e37c1fe1df264d00ada64279e920e949"
            ],
            "layout": "IPY_MODEL_3ffdee5cfbd3495f8817f272b39e2832"
          }
        },
        "458ea1863e87427c9c4608b7cad4c33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27bbc41196da431fbca54a7f9c343e8e",
            "placeholder": "​",
            "style": "IPY_MODEL_c14fb51b4f2749f181997c9f5d60f2b0",
            "value": "Augmentation: 100%"
          }
        },
        "7f537bf377cb46f6b0e9be120ac2b983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d41687e8fad45fb9f49981cdec45758",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68daed86d0414c128db7c33f065c5845",
            "value": 40
          }
        },
        "e37c1fe1df264d00ada64279e920e949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79667e7df5b14808be3421fbc04d6295",
            "placeholder": "​",
            "style": "IPY_MODEL_bfec288288c946d29d7d1a88dafe9da5",
            "value": " 40/40 [00:02&lt;00:00, 17.88 reps/s, subject=s40]"
          }
        },
        "3ffdee5cfbd3495f8817f272b39e2832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27bbc41196da431fbca54a7f9c343e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14fb51b4f2749f181997c9f5d60f2b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d41687e8fad45fb9f49981cdec45758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68daed86d0414c128db7c33f065c5845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79667e7df5b14808be3421fbc04d6295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfec288288c946d29d7d1a88dafe9da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d4b27809aef466fb035d2d0ad358b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66cbb7407663443798a547f25a1ea1ad",
              "IPY_MODEL_11ea4d4688aa4c37aa6e69113eb63b3d",
              "IPY_MODEL_8f2e2565ec8e42569ebe41cf18fd0897"
            ],
            "layout": "IPY_MODEL_15a3e65ca9104e7abf8a2e2c2176d34d"
          }
        },
        "66cbb7407663443798a547f25a1ea1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e867fee068148cc8fc42a86ba8e2cdf",
            "placeholder": "​",
            "style": "IPY_MODEL_ffe41b37dfe14b49a0e7e5b6765e48ff",
            "value": "Preprocessing: 100%"
          }
        },
        "11ea4d4688aa4c37aa6e69113eb63b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6beb5d5b814454cbfb8350d42eab23a",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1201fc638b9402485eee301981c3e96",
            "value": 40
          }
        },
        "8f2e2565ec8e42569ebe41cf18fd0897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_155cf3fa8ef14859bc90393043cda238",
            "placeholder": "​",
            "style": "IPY_MODEL_7d1bebb4be7f4464b67f8d19d1e8cec3",
            "value": " 40/40 [00:01&lt;00:00, 39.43 reps/s, subject=s40]"
          }
        },
        "15a3e65ca9104e7abf8a2e2c2176d34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e867fee068148cc8fc42a86ba8e2cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe41b37dfe14b49a0e7e5b6765e48ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6beb5d5b814454cbfb8350d42eab23a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1201fc638b9402485eee301981c3e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "155cf3fa8ef14859bc90393043cda238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d1bebb4be7f4464b67f8d19d1e8cec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}